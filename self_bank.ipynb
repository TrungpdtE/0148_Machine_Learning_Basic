{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import random\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Dataset\n",
    "df = pd.read_csv(\"GK_dataset/bank.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating User Columns\n",
    "df_user = pd.DataFrame(np.arange(0,len(df)), columns=['user'])\n",
    "df = pd.concat([df_user, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 18 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   user       4521 non-null   int64 \n",
      " 1   age        4521 non-null   int64 \n",
      " 2   job        4521 non-null   object\n",
      " 3   marital    4521 non-null   object\n",
      " 4   education  4521 non-null   object\n",
      " 5   default    4521 non-null   object\n",
      " 6   balance    4521 non-null   int64 \n",
      " 7   housing    4521 non-null   object\n",
      " 8   loan       4521 non-null   object\n",
      " 9   contact    4521 non-null   object\n",
      " 10  day        4521 non-null   int64 \n",
      " 11  month      4521 non-null   object\n",
      " 12  duration   4521 non-null   int64 \n",
      " 13  campaign   4521 non-null   int64 \n",
      " 14  pdays      4521 non-null   int64 \n",
      " 15  previous   4521 non-null   int64 \n",
      " 16  poutcome   4521 non-null   object\n",
      " 17  y          4521 non-null   object\n",
      "dtypes: int64(8), object(10)\n",
      "memory usage: 635.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1787</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>oct</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4789</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1350</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>apr</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1476</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  age          job  marital  education default  balance housing loan  \\\n",
       "0     0   30   unemployed  married    primary      no     1787      no   no   \n",
       "1     1   33     services  married  secondary      no     4789     yes  yes   \n",
       "2     2   35   management   single   tertiary      no     1350     yes   no   \n",
       "3     3   30   management  married   tertiary      no     1476     yes  yes   \n",
       "4     4   59  blue-collar  married  secondary      no        0     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  cellular   19   oct        79         1     -1         0  unknown  no  \n",
       "1  cellular   11   may       220         1    339         4  failure  no  \n",
       "2  cellular   16   apr       185         1    330         1  failure  no  \n",
       "3   unknown    3   jun       199         4     -1         0  unknown  no  \n",
       "4   unknown    5   may       226         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 827,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4516</th>\n",
       "      <td>4516</td>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-333</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>30</td>\n",
       "      <td>jul</td>\n",
       "      <td>329</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4517</th>\n",
       "      <td>4517</td>\n",
       "      <td>57</td>\n",
       "      <td>self-employed</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>yes</td>\n",
       "      <td>-3313</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>9</td>\n",
       "      <td>may</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4518</th>\n",
       "      <td>4518</td>\n",
       "      <td>57</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>295</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>aug</td>\n",
       "      <td>151</td>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>4519</td>\n",
       "      <td>28</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>1137</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>6</td>\n",
       "      <td>feb</td>\n",
       "      <td>129</td>\n",
       "      <td>4</td>\n",
       "      <td>211</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>4520</td>\n",
       "      <td>44</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1136</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>3</td>\n",
       "      <td>apr</td>\n",
       "      <td>345</td>\n",
       "      <td>2</td>\n",
       "      <td>249</td>\n",
       "      <td>7</td>\n",
       "      <td>other</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  age            job  marital  education default  balance housing  \\\n",
       "4516  4516   33       services  married  secondary      no     -333     yes   \n",
       "4517  4517   57  self-employed  married   tertiary     yes    -3313     yes   \n",
       "4518  4518   57     technician  married  secondary      no      295      no   \n",
       "4519  4519   28    blue-collar  married  secondary      no     1137      no   \n",
       "4520  4520   44   entrepreneur   single   tertiary      no     1136     yes   \n",
       "\n",
       "     loan   contact  day month  duration  campaign  pdays  previous poutcome  \\\n",
       "4516   no  cellular   30   jul       329         5     -1         0  unknown   \n",
       "4517  yes   unknown    9   may       153         1     -1         0  unknown   \n",
       "4518   no  cellular   19   aug       151        11     -1         0  unknown   \n",
       "4519   no  cellular    6   feb       129         4    211         3    other   \n",
       "4520  yes  cellular    3   apr       345         2    249         7    other   \n",
       "\n",
       "       y  \n",
       "4516  no  \n",
       "4517  no  \n",
       "4518  no  \n",
       "4519  no  \n",
       "4520  no  "
      ]
     },
     "execution_count": 828,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['user', 'age', 'job', 'marital', 'education', 'default', 'balance',\n",
       "       'housing', 'loan', 'contact', 'day', 'month', 'duration',\n",
       "       'campaign', 'pdays', 'previous', 'poutcome', 'y'], dtype=object)"
      ]
     },
     "execution_count": 829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Annalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2260.000000</td>\n",
       "      <td>41.170095</td>\n",
       "      <td>1422.657819</td>\n",
       "      <td>15.915284</td>\n",
       "      <td>263.961292</td>\n",
       "      <td>2.793630</td>\n",
       "      <td>39.766645</td>\n",
       "      <td>0.542579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1305.244613</td>\n",
       "      <td>10.576211</td>\n",
       "      <td>3009.638142</td>\n",
       "      <td>8.247667</td>\n",
       "      <td>259.856633</td>\n",
       "      <td>3.109807</td>\n",
       "      <td>100.121124</td>\n",
       "      <td>1.693562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>-3313.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1130.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2260.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>444.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3390.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1480.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4520.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>71188.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3025.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user          age       balance          day     duration  \\\n",
       "count  4521.000000  4521.000000   4521.000000  4521.000000  4521.000000   \n",
       "mean   2260.000000    41.170095   1422.657819    15.915284   263.961292   \n",
       "std    1305.244613    10.576211   3009.638142     8.247667   259.856633   \n",
       "min       0.000000    19.000000  -3313.000000     1.000000     4.000000   \n",
       "25%    1130.000000    33.000000     69.000000     9.000000   104.000000   \n",
       "50%    2260.000000    39.000000    444.000000    16.000000   185.000000   \n",
       "75%    3390.000000    49.000000   1480.000000    21.000000   329.000000   \n",
       "max    4520.000000    87.000000  71188.000000    31.000000  3025.000000   \n",
       "\n",
       "          campaign        pdays     previous  \n",
       "count  4521.000000  4521.000000  4521.000000  \n",
       "mean      2.793630    39.766645     0.542579  \n",
       "std       3.109807   100.121124     1.693562  \n",
       "min       1.000000    -1.000000     0.000000  \n",
       "25%       1.000000    -1.000000     0.000000  \n",
       "50%       2.000000    -1.000000     0.000000  \n",
       "75%       3.000000    -1.000000     0.000000  \n",
       "max      50.000000   871.000000    25.000000  "
      ]
     },
     "execution_count": 831,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of the columns:\n",
      " user          int64\n",
      "age           int64\n",
      "job          object\n",
      "marital      object\n",
      "education    object\n",
      "default      object\n",
      "balance       int64\n",
      "housing      object\n",
      "loan         object\n",
      "contact      object\n",
      "day           int64\n",
      "month        object\n",
      "duration      int64\n",
      "campaign      int64\n",
      "pdays         int64\n",
      "previous      int64\n",
      "poutcome     object\n",
      "y            object\n",
      "dtype: object\n",
      "            user        age      balance        day    duration  campaign  \\\n",
      "y                                                                           \n",
      "no   2261.324500  40.998000  1403.211750  15.948750  226.347500  2.862250   \n",
      "yes  2249.831094  42.491363  1571.955854  15.658349  552.742802  2.266795   \n",
      "\n",
      "         pdays  previous  \n",
      "y                         \n",
      "no   36.006000  0.471250  \n",
      "yes  68.639155  1.090211  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check the data types of the columns\n",
    "print(\"Data types of the columns:\\n\", df.dtypes)\n",
    "\n",
    "# Select only the numeric columns for the mean calculation\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Perform the groupby operation on the numeric columns\n",
    "if 'y' in df.columns:\n",
    "    result = df.groupby('y')[numeric_df.columns].mean()\n",
    "    print(result)\n",
    "else:\n",
    "    print(\"Column 'y' does not exist in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['user', 'age', 'job', 'marital', 'education', 'default', 'balance',\n",
      "       'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign',\n",
      "       'pdays', 'previous', 'poutcome', 'y'],\n",
      "      dtype='object')\n",
      "y\n",
      "no     4000\n",
      "yes     521\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the columns of the DataFrame\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# Verify the existence of the column 'y'\n",
    "if 'y' in df.columns:\n",
    "    # Perform the value_counts operation if the column exists\n",
    "    print(df['y'].value_counts())\n",
    "else:\n",
    "    print(\"Column 'y' does not exist in the DataFrame.\")\n",
    "    # Additional steps to handle the missing column can be added here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of \"No\": 88.476%\n",
      "Percentage of \"Yes\": 11.524%\n"
     ]
    }
   ],
   "source": [
    "countNo = len(df[df.y == 'no'])\n",
    "countYes = len(df[df.y == 'yes'])\n",
    "print('Percentage of \"No\": {:.3f}%'. format((countNo/(len(df.y))*100)))\n",
    "print('Percentage of \"Yes\": {:.3f}%'. format((countYes/(len(df.y))*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Verifying null values\n",
    "# sns.heatmap(df.isnull(), yticklabels=False, cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user         False\n",
       "age          False\n",
       "job          False\n",
       "marital      False\n",
       "education    False\n",
       "default      False\n",
       "balance      False\n",
       "housing      False\n",
       "loan         False\n",
       "contact      False\n",
       "day          False\n",
       "month        False\n",
       "duration     False\n",
       "campaign     False\n",
       "pdays        False\n",
       "previous     False\n",
       "poutcome     False\n",
       "y            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user         0\n",
       "age          0\n",
       "job          0\n",
       "marital      0\n",
       "education    0\n",
       "default      0\n",
       "balance      0\n",
       "housing      0\n",
       "loan         0\n",
       "contact      0\n",
       "day          0\n",
       "month        0\n",
       "duration     0\n",
       "campaign     0\n",
       "pdays        0\n",
       "previous     0\n",
       "poutcome     0\n",
       "y            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in X: ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous', 'default']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in X:\", X.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X shape: (4521, 7)\n",
      "y shape: (4521,)\n"
     ]
    }
   ],
   "source": [
    "#Define X and y\n",
    "X = df.drop(['y','user','job','marital', 'education', 'contact', \n",
    "             'housing', 'loan', 'day', 'month', 'poutcome' ], axis=1)\n",
    "y = df['y']\n",
    "\n",
    "\n",
    "# In ra thông tin về kích thước của X và y\n",
    "print(\"\\nX shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Dummies Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy Trap¶\n",
    "Dummy Variable Trap can influence negatively in our analyses. Dummy Variable trap is a scenario in which the independent variables are multicollinear - a scenario in which two or more variables are highly correlated; in simple terms, one variable can be predicted from the others. The best definition for Dummy Variable Trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age  balance  duration  campaign  pdays  previous  default\n",
      "0      30     1787        79         1     -1         0    False\n",
      "1      33     4789       220         1    339         4    False\n",
      "2      35     1350       185         1    330         1    False\n",
      "3      30     1476       199         4     -1         0    False\n",
      "4      59        0       226         1     -1         0    False\n",
      "...   ...      ...       ...       ...    ...       ...      ...\n",
      "4516   33     -333       329         5     -1         0    False\n",
      "4517   57    -3313       153         1     -1         0     True\n",
      "4518   57      295       151        11     -1         0    False\n",
      "4519   28     1137       129         4    211         3    False\n",
      "4520   44     1136       345         2    249         7    False\n",
      "\n",
      "[4521 rows x 7 columns]\n",
      "         y\n",
      "0     True\n",
      "1     True\n",
      "2     True\n",
      "3     True\n",
      "4     True\n",
      "...    ...\n",
      "4516  True\n",
      "4517  True\n",
      "4518  True\n",
      "4519  True\n",
      "4520  True\n",
      "\n",
      "[4521 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "X.columns\n",
    "X = X.drop(['default_no'], axis= 1)\n",
    "X = X.rename(columns = {'default_yes': 'default'})\n",
    "y.columns\n",
    "y = y.drop(['yes'], axis=1)\n",
    "y = y.rename(columns= {'no': 'y'})\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3616, 7) (905, 7) (3616, 1) (905, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing the Traing Set¶\n",
    "The Training Set is unbalanced. And so become necessary to organize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "True     3199\n",
       "False     417\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_index = y_train[y_train.values == 1].index\n",
    "neg_index = y_train[y_train.values == 0].index\n",
    "\n",
    "if len(pos_index) > len(neg_index):\n",
    "    higher = pos_index\n",
    "    lower = neg_index\n",
    "else:\n",
    "    higher = neg_index\n",
    "    lower = pos_index\n",
    "\n",
    "random.seed(0)\n",
    "higher = np.random.choice(higher, size=len(lower))\n",
    "lower = np.asarray(lower)\n",
    "new_indexes = np.concatenate((lower, higher))\n",
    "\n",
    "X_train = X_train.loc[new_indexes]\n",
    "y_train = y_train.loc[new_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "False    417\n",
       "True     417\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train2 = pd.DataFrame(sc.fit_transform(X_train))\n",
    "X_test2 = pd.DataFrame(sc.transform(X_test))\n",
    "X_train2.columns = X_train.columns.values\n",
    "X_test2.columns = X_test.columns.values\n",
    "X_train2.index = X_train.index.values\n",
    "X_test2.index = X_test.index.values\n",
    "X_train = X_train2\n",
    "X_test = X_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building¶\n",
    "Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "## Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "results = pd.DataFrame([['Logistic Regression (Lasso)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3n/zck8b8fs0rvdfvltbjxwz55h0000gn/T/ipykernel_42847/3589353506.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m model_results = pd.DataFrame([['K-Nearest Neighbors (minkowski)', acc, prec, rec, f1]],\n\u001b[1;32m     14\u001b[0m                \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F1 Score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "## K-Nearest Neighbors (K-NN)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=15, metric='minkowski')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['K-Nearest Neighbors (minkowski)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM (Linear)\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(random_state = 0, kernel = 'linear', probability= True)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['SVM (Linear)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM (rbf)\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(random_state = 0, kernel = 'rbf', probability= True)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['SVM (RBF)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['Naive Bayes (Gaussian)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#Predicting the best set result\n",
    "y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['Decision Tree', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest Gini (n=100)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(random_state = 0, n_estimators = 100,\n",
    "                                    criterion = 'gini')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['Random Forest Gini (n=100)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest Gini (n=200)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(random_state = 0, n_estimators = 200,\n",
    "                                    criterion = 'gini')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['Random Forest Gini (n=200)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest Gini (n=300)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(random_state = 0, n_estimators = 300,\n",
    "                                    criterion = 'gini')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['Random Forest Gini (n=300)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest Entropy (n=100)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(random_state = 0, n_estimators = 100,\n",
    "                                    criterion = 'entropy')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['Random Forest Entropy (n=100)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest Entropy (n=200)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(random_state = 0, n_estimators = 200,\n",
    "                                    criterion = 'entropy')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['Random Forest Entropy (n=200)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest Entropy (n=300)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(random_state = 0, n_estimators = 300,\n",
    "                                    criterion = 'entropy')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['Random Forest Entropy (n=300)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results\n",
    "The SVM (Linear) was the most powerful method for our model as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying K-fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train,cv=10)\n",
    "accuracies.mean()\n",
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM (Linear) Accuracy: %0.3f (+/- %0.3f)\" % (accuracies.mean(), accuracies.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\n",
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(df_cm, annot=True, fmt='g')\n",
    "print(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linkcode\n",
    "Accuracy Paradox\n",
    "Accuracy is not the best way to measure a perfomance of model. It´s because Accuracy Paradox. More about Accuracy Paradox here.\n",
    "\n",
    "Cumulative Accuracy Profile (CAP)\n",
    "For figure out Accuracy Paradox, we will use the Cumulative Accuracy Profile (CAP). More about Cumulative Accuracy Profile (CAP) here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cumulative Accuracy Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Cumulative Accuracy Profile (CAP)\n",
    "y_pred_proba = classifier.predict_proba(X=X_test)\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import integrate\n",
    "def capcurve(y_values, y_preds_proba):\n",
    "    num_pos_obs = np.sum(y_values)\n",
    "    num_count = len(y_values)\n",
    "    rate_pos_obs = float(num_pos_obs) / float(num_count)\n",
    "    ideal = pd.DataFrame({'x':[0,rate_pos_obs,1],'y':[0,1,1]})\n",
    "    xx = np.arange(num_count) / float(num_count - 1)\n",
    "    \n",
    "    y_cap = np.c_[y_values,y_preds_proba]\n",
    "    y_cap_df_s = pd.DataFrame(data=y_cap)\n",
    "    y_cap_df_s = y_cap_df_s.sort_values([1], ascending=False).reset_index(level = y_cap_df_s.index.names, drop=True)\n",
    "    \n",
    "    print(y_cap_df_s.head(20))\n",
    "    \n",
    "    yy = np.cumsum(y_cap_df_s[0]) / float(num_pos_obs)\n",
    "    yy = np.append([0], yy[0:num_count-1]) #add the first curve point (0,0) : for xx=0 we have yy=0\n",
    "    \n",
    "    percent = 0.5\n",
    "    row_index = int(np.trunc(num_count * percent))\n",
    "    \n",
    "    val_y1 = yy[row_index]\n",
    "    val_y2 = yy[row_index+1]\n",
    "    if val_y1 == val_y2:\n",
    "        val = val_y1*1.0\n",
    "    else:\n",
    "        val_x1 = xx[row_index]\n",
    "        val_x2 = xx[row_index+1]\n",
    "        val = val_y1 + ((val_x2 - percent)/(val_x2 - val_x1))*(val_y2 - val_y1)\n",
    "    \n",
    "    sigma_ideal = 1 * xx[num_pos_obs - 1 ] / 2 + (xx[num_count - 1] - xx[num_pos_obs]) * 1\n",
    "    sigma_model = integrate.simps(yy,xx)\n",
    "    sigma_random = integrate.simps(xx,xx)\n",
    "    \n",
    "    ar_value = (sigma_model - sigma_random) / (sigma_ideal - sigma_random)\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 1)\n",
    "    ax.plot(ideal['x'],ideal['y'], color='grey', label='Perfect Model')\n",
    "    ax.plot(xx,yy, color='red', label='User Model')\n",
    "    ax.plot(xx,xx, color='blue', label='Random Model')\n",
    "    ax.plot([percent, percent], [0.0, val], color='green', linestyle='--', linewidth=1)\n",
    "    ax.plot([0, percent], [val, val], color='green', linestyle='--', linewidth=1, label=str(val*100)+'% of positive obs at '+str(percent*100)+'%')\n",
    "    \n",
    "    plt.xlim(0, 1.02)\n",
    "    plt.ylim(0, 1.25)\n",
    "    plt.title(\"CAP Curve - a_r value =\"+str(ar_value))\n",
    "    plt.xlabel('% of the data')\n",
    "    plt.ylabel('% of positive obs')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capcurve(y_test,y_pred_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing Coefficients\n",
    "pd.concat([pd.DataFrame(X_train.columns, columns = [\"features\"]),\n",
    "           pd.DataFrame(np.transpose(classifier.coef_), columns = [\"coef\"])\n",
    "           ],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linkcode\n",
    "Feature Selection\n",
    "Recursive Feature Elimination\n",
    "For feature selection, we wil use the Recursive Feature Elimination (RFE). More about Recursive Feature Elimination (RFE) here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Model to Test\n",
    "classifier = SVC(random_state = 0, kernel = 'linear', probability= True)\n",
    "\n",
    "# Select Best X Features\n",
    "rfe = RFE(classifier, n_features_to_select=None)\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Correlation Matrix\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = X_train[X_train.columns[rfe.support_]].corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(18, 15))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Model to the Training Set\n",
    "classifier = SVC(random_state = 0, kernel = 'linear', probability= True)\n",
    "classifier.fit(X_train[X_train.columns[rfe.support_]], y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test[X_train.columns[rfe.support_]])\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['SVM RFE (Linear)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Results\n",
    "#Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "sns.heatmap(data=cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying k-Fold Cross Validation (RFE)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier,\n",
    "                             X = X_train[X_train.columns[rfe.support_]],\n",
    "                             y = y_train, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM RFE (Linear) Accuracy: %0.3f (+/- %0.3f)\" % (accuracies.mean(), accuracies.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing Coefficients\n",
    "pd.concat([pd.DataFrame(X_train[X_train.columns[rfe.support_]].columns, columns = [\"features\"]),\n",
    "           pd.DataFrame(np.transpose(classifier.coef_), columns = [\"coef\"])\n",
    "           ],axis = 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAP Curve\n",
    "y_pred_proba = classifier.predict_proba(X=X_test[X_train.columns[rfe.support_]])\n",
    "capcurve(y_test,y_pred_proba[:,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### End of Model ####\n",
    "\n",
    "# Formatting Final Results\n",
    "user_identifier = df['user']\n",
    "final_results = pd.concat([y_test, user_identifier], axis = 1).dropna()\n",
    "final_results['predicted'] = y_pred\n",
    "final_results = final_results[['user', 'y', 'predicted']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
