{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f0f990-4df7-478c-b13d-e6f96ce17061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset \n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b78c6f37-58b7-4568-8b91-c09ca036dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "151c0717-004b-40a2-878c-359958217fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the features -> all are numeric\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cadf8c8-38cc-4889-9eea-46d2d396607f",
   "metadata": {},
   "source": [
    "# Sequential and Non Sequential Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6242131-a201-4e1e-a8ea-3e2e91f78eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                270       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential model with one output\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "keras.layers.Dense(30, activation=\"relu\",input_shape=X_train.shape[1:]),\n",
    "# one output\n",
    "keras.layers.Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5022d9a5-d1b2-4e95-9bca-78b73f79313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.8280 - val_loss: 0.9038\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6854 - val_loss: 0.5985\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5658 - val_loss: 1.6154\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5154 - val_loss: 0.4559\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4437 - val_loss: 0.4295\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4330 - val_loss: 0.4380\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4262 - val_loss: 0.4044\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4150 - val_loss: 0.4089\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4089 - val_loss: 0.4046\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4083 - val_loss: 0.4056\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4010 - val_loss: 0.3881\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3959 - val_loss: 0.3952\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3957 - val_loss: 0.3994\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3953 - val_loss: 0.3869\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3878 - val_loss: 0.3838\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3824 - val_loss: 0.3700\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3771 - val_loss: 0.3791\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3802 - val_loss: 0.3847\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3805 - val_loss: 0.3685\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3714 - val_loss: 0.3747\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3778\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5db821-b8f9-4224-b3ff-ac0be2fdefd8",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfc0cd86-86d5-4913-8eb1-78628cab7151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This mimics scikit regressor; so we can do randomsearchcv etc\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3,input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "387c46b3-075a-4ff1-a735-fcd770526a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\AppData\\Local\\Temp/ipykernel_7124/1357716075.py:3: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    }
   ],
   "source": [
    "# wrapper for sci-kit, now it can use fit, score and predict\n",
    "\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d987e4a-f80c-4414-ae74-1387cb9e4a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 4.8267 - val_loss: 3.1822\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.7499 - val_loss: 1.2972\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9429 - val_loss: 0.8132\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7201 - val_loss: 0.6745\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6529 - val_loss: 0.6308\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.5797\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 3.8423 - val_loss: 2.1584\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4855 - val_loss: 1.1201\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9239 - val_loss: 0.8392\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7661 - val_loss: 0.7493\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7128 - val_loss: 0.7110\n",
      "121/121 [==============================] - ETA: 0s - loss: 0.717 - 0s 2ms/step - loss: 0.7116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 4.3722 - val_loss: 3.3854\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.5026 - val_loss: 1.4439\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8575 - val_loss: 0.8908\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6812 - val_loss: 0.7134\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6265 - val_loss: 0.6531\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.6545\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7915 - val_loss: 0.6075\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5611 - val_loss: 0.5063\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4956 - val_loss: 0.6760\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4898 - val_loss: 0.5084\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4364 - val_loss: 0.4203\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3817\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8808 - val_loss: 0.9278\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5111 - val_loss: 0.4473\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4424 - val_loss: 0.4210\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4186 - val_loss: 0.3981\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3994 - val_loss: 0.3859\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4006\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 4ms/step - loss: 0.8421 - val_loss: 1.0431\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5374 - val_loss: 0.4869\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4375 - val_loss: 0.4584\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4032 - val_loss: 0.4144\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3825 - val_loss: 0.4249\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4446\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 3ms/step - loss: 1.8149 - val_loss: 0.7837\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7020 - val_loss: 0.6550\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6090 - val_loss: 0.5634\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5659 - val_loss: 0.5743\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5360 - val_loss: 0.5059\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4859\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: 1.2071 - val_loss: 0.7223\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6955 - val_loss: 0.6528\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6327 - val_loss: 0.6057\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5881 - val_loss: 0.5664\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5532 - val_loss: 0.5478\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.5771\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.5479 - val_loss: 1.2165\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6732 - val_loss: 0.6883\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6151 - val_loss: 0.7472\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5975 - val_loss: 0.5915\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5312 - val_loss: 0.6270\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.5819\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9515 - val_loss: 0.5923\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5869 - val_loss: 0.5997\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4997 - val_loss: 0.4880\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4639 - val_loss: 0.4754\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4493 - val_loss: 0.4973\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4039\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.9939 - val_loss: 0.5609\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4980 - val_loss: 0.4210\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4308 - val_loss: 0.3898\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4135 - val_loss: 0.3950\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4298 - val_loss: 0.3770\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3965\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9152 - val_loss: 0.9314\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5608 - val_loss: 0.4741\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4578 - val_loss: 0.4447\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4370 - val_loss: 0.4301\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4223 - val_loss: 0.4170\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4607\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 3.1752 - val_loss: 1.0115\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7544 - val_loss: 0.6268\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6106 - val_loss: 0.5865\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5916 - val_loss: 0.5728\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5821 - val_loss: 0.5666\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.5392\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 3.2257 - val_loss: 1.0893\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7406 - val_loss: 0.6344\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5849 - val_loss: 0.5850\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5670 - val_loss: 0.5727\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5586 - val_loss: 0.5636\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.5695\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: 3.4241 - val_loss: 1.0874\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7389 - val_loss: 0.6226\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5727 - val_loss: 0.5753\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5542 - val_loss: 0.5634\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5479 - val_loss: 0.5562\n",
      "121/121 [==============================] - ETA: 0s - loss: 0.580 - 0s 2ms/step - loss: 0.5789\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: 1.2265 - val_loss: 0.6723\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6323 - val_loss: 0.5625\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5522 - val_loss: 0.5097\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5017 - val_loss: 0.4605\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4683 - val_loss: 0.4307\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4176\n",
      "Epoch 1/5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.3323 - val_loss: 0.6121\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5772 - val_loss: 0.5394\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5220 - val_loss: 0.4944\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4850 - val_loss: 0.4659\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4586 - val_loss: 0.4361\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4479\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 4ms/step - loss: 0.9522 - val_loss: 0.5820\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5392 - val_loss: 0.5286\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4908 - val_loss: 0.4895\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4568 - val_loss: 0.4637\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4286 - val_loss: 0.4316\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4641\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0603 - val_loss: 0.6443\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5312 - val_loss: 0.4472\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4801 - val_loss: 0.4163\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4635 - val_loss: 0.4356\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4446 - val_loss: 0.4030\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3909\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 3ms/step - loss: 1.0179 - val_loss: 148.1796\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 39.0860 - val_loss: 250.7141\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7308 - val_loss: 1.9268\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9262 - val_loss: 0.8400\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4581 - val_loss: 0.4616\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4183 - val_loss: 0.4152\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3944 - val_loss: 0.4397\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4656\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 2.9854 - val_loss: 1.7564\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2503 - val_loss: 1.0365\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8755 - val_loss: 0.7948\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7623 - val_loss: 0.7066\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7164 - val_loss: 0.6684\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.6494\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 2.9828 - val_loss: 1.7584\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1745 - val_loss: 1.0282\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8321 - val_loss: 0.7859\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7355 - val_loss: 0.7056\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6981 - val_loss: 0.6725\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.7004\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 3.2030 - val_loss: 1.7162\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2090 - val_loss: 1.0227\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8564 - val_loss: 0.8283\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7599 - val_loss: 0.7488\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7177 - val_loss: 0.7065\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.7551\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: 1.6428 - val_loss: 0.7175\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7052 - val_loss: 0.6322\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6377 - val_loss: 0.5852\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5931 - val_loss: 0.5502\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5593 - val_loss: 0.5216\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5084\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: 1.8532 - val_loss: 0.7655\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7013 - val_loss: 0.6548\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6362 - val_loss: 0.6072\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6006 - val_loss: 0.5733\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5697 - val_loss: 0.5452\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.5722\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: 1.6470 - val_loss: 0.8007\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7122 - val_loss: 0.6645\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6362 - val_loss: 0.6115\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5899 - val_loss: 0.5756\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5569 - val_loss: 0.5539\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.5958\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.7140 - val_loss: 0.9101\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8101 - val_loss: 0.7171\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7096 - val_loss: 0.6490\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6512 - val_loss: 0.6023\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6074 - val_loss: 0.5682\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.5582\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4770 - val_loss: 0.8278\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7538 - val_loss: 0.7034\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6687 - val_loss: 0.6382\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6157 - val_loss: 0.6014\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5724 - val_loss: 0.5469\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.5700\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4327 - val_loss: 0.8062\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7386 - val_loss: 0.7146\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6639 - val_loss: 0.6483\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6188 - val_loss: 0.6091\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5831 - val_loss: 0.5818\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.6165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [-0.64860596 -0.40896992 -0.54830353 -0.42037062 -0.56252042 -0.44318431\n",
      "         nan -0.70167126 -0.55877342 -0.58155352]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 0.7534 - val_loss: 1.5683\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4661 - val_loss: 0.4465\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4074 - val_loss: 0.3744\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3795 - val_loss: 0.3668\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3683 - val_loss: 0.3692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x000001AC5AAAD2B0>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001AC529211F0>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10,cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=5,\n",
    "validation_data=(X_valid, y_valid),\n",
    "callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80d9ad97-96e7-4349-aeec-2fefc9b5d466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.016880878822421123, 'n_hidden': 2, 'n_neurons': 24}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
