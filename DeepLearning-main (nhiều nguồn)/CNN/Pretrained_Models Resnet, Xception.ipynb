{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20527062-d2c1-4b81-87b1-f33ce27432f3",
   "metadata": {},
   "source": [
    "# Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba846287-aaee-4501-bcc7-1c869ad7aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_sample_image\n",
    "\n",
    "# Load sample images\n",
    "# Pixel intesities vary between 0-255, scale to 0-1\n",
    "china = load_sample_image(\"china.jpg\") / 255\n",
    "flower = load_sample_image(\"flower.jpg\") / 255\n",
    "images = np.array([china, flower])\n",
    "batch_size, height, width, channels = images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6593f5d2-fed0-4ad5-8953-4d4db2c3684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize image -> resnet expects 224X224\n",
    "import tensorflow as tf \n",
    "\n",
    "images_resized = tf.image.resize(images,[224,224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495b9887-7576-4a99-bd30-0576b555a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our images are in scale 0-1; preprocess function assumes it is from 0-255, so multiply back\n",
    "inputs = keras.applications.resnet50.preprocess_input(images_resized *255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ae39f-35d8-41d1-9b2f-68a94cefed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_proba = model.predict(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01d2831-5c27-4867-924c-aee54a789581",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_K = keras.applications.resnet50.decode_predictions(Y_proba, top=3)\n",
    "for image_index in range(len(images)):\n",
    "    print(\"Image #{}\".format(image_index))\n",
    "    for class_id, name, y_proba in top_K[image_index]:\n",
    "        print(\" {} - {:12s} {:.2f}%\".format(class_id, name, y_proba *100))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7705b3-9785-4759-b505-442eb751a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall  tensorflow_datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a57545-2c23-42bb-9d3e-27b499795a41",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6695383e-4ff6-435d-8a96-8a91a17af74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found a different version 3.0.1 of dataset tf_flowers in data_dir C:\\Users\\91760\\tensorflow_datasets. Using currently defined version 1.0.0.\n"
     ]
    }
   ],
   "source": [
    "# Use Xception \n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf \n",
    "\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "(train_set, test_set, valid_set), info = tfds.load(\"tf_flowers\",\n",
    "                          split=[\n",
    "                                tfds.Split.TRAIN.subsplit(tfds.percent[:70]),\n",
    "                                tfds.Split.TRAIN.subsplit(tfds.percent[70:85]),\n",
    "                                tfds.Split.TRAIN.subsplit(tfds.percent[85:]),\n",
    "                              \n",
    "                              \n",
    "                          ],\n",
    "                          as_supervised=True,with_info=True)\n",
    "\n",
    "#info -> setting with_info = True\n",
    "\n",
    "dataset_size = info.splits[\"train\"].num_examples # 3670\n",
    "class_names = info.features[\"label\"].names # [\"dandelion\", \"daisy\", ...]\n",
    "n_classes = info.features[\"label\"].num_classes # 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdb0d345-60f7-4423-9a02-3356a09a6120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "        resized_image = tf.image.resize(image, [224, 224])\n",
    "        final_image = keras.applications.xception.preprocess_input(resized_image)\n",
    "        return final_image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "103fb47d-b48c-42e9-bd29-2c5f6ec29796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras \n",
    "\n",
    "batch_size = 32\n",
    "train_set = train_set.shuffle(1000)\n",
    "train_set = train_set.map(preprocess).batch(batch_size).prefetch(1)\n",
    "valid_set = valid_set.map(preprocess).batch(batch_size).prefetch(1)\n",
    "test_set = test_set.map(preprocess).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c010416-7d58-4610-97c9-e26ed7bcbf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the top layer ie the global average pooling layer + dense output layer\n",
    "base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "# add new gobal layer + Dense output layer\n",
    "\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
    "\n",
    "# keras model outputs = output implies using the new model\n",
    "model = keras.Model(inputs=base_model.input, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ff70606-e636-444a-8a36-6d4efc1da0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the base layers in the initial layers of training\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b9280f9-66e9-4d15-b956-aa691320539c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "81/81 [==============================] - 217s 3s/step - loss: 1.6161 - accuracy: 0.7838 - val_loss: 1.0758 - val_accuracy: 0.8574\n",
      "Epoch 2/2\n",
      "38/81 [=============>................] - ETA: 1:41 - loss: 0.4977 - accuracy: 0.8964Collecting tensorflow-gpu\n",
      "  Downloading tensorflow_gpu-2.7.0-cp37-cp37m-win_amd64.whl (430.8 MB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorflow-gpu) (3.10.0.2)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorflow-gpu) (0.15.0)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp37-cp37m-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorflow-gpu) (3.19.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorflow-gpu) (0.3.3)\n",
      "Collecting keras<2.8,>=2.7.0rc0\n",
      "  Using cached keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Collecting flatbuffers<3.0,>=1.12\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorflow-gpu) (1.13.3)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorflow-gpu) (1.21.2)\n",
      "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
      "  Using cached tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorflow-gpu) (0.37.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorflow-gpu) (1.42.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-12.0.0-2-py2.py3-none-win_amd64.whl (13.0 MB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (2.27.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (58.0.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (1.6.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (1.33.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (0.4.4)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (3.3.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu) (4.8.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (3.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\91760\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu) (3.7.0)\n",
      "Installing collected packages: tensorboard-data-server, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, libclang, keras, flatbuffers, tensorflow-gpu\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.6.0\n",
      "    Uninstalling tensorflow-estimator-2.6.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.4.0\n",
      "    Uninstalling tensorboard-2.4.0:\n",
      "      Successfully uninstalled tensorboard-2.4.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.3.1\n",
      "    Uninstalling Keras-2.3.1:\n",
      "      Successfully uninstalled Keras-2.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /simple/tensorboard/\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\91760\\\\anaconda3\\\\envs\\\\tensorflow_gpu\\\\Lib\\\\site-packages\\\\tensorflow\\\\lite\\\\experimental\\\\microfrontend\\\\python\\\\ops\\\\_audio_microfrontend_op.so'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 230s 3s/step - loss: 0.5301 - accuracy: 0.8992 - val_loss: 0.9113 - val_accuracy: 0.8722\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.2, momentum=0.9, decay=0.01)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, epochs=2, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f00c5adb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (540, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1048/1190143266.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mY_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtop_K\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_proba\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Image #{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\resnet.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[1;34m(preds, top)\u001b[0m\n\u001b[0;32m    528\u001b[0m               'keras.applications.resnet.decode_predictions')\n\u001b[0;32m    529\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mimagenet_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\imagenet_utils.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[1;34m(preds, top)\u001b[0m\n\u001b[0;32m    149\u001b[0m                      \u001b[1;34m'a batch of predictions '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m                      \u001b[1;34m'(i.e. a 2D array of shape (samples, 1000)). '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m                      'Found array with shape: ' + str(preds.shape))\n\u001b[0m\u001b[0;32m    152\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mCLASS_INDEX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     fpath = data_utils.get_file(\n",
      "\u001b[1;31mValueError\u001b[0m: `decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (540, 5)"
     ]
    }
   ],
   "source": [
    "Y_proba = model.predict(test_set)\n",
    "\n",
    "top_K = keras.applications.resnet50.decode_predictions(Y_proba, top=3)\n",
    "for image_index in range(len(images)):\n",
    "        print(\"Image #{}\".format(image_index))\n",
    "        for class_id, name, y_proba in top_K[image_index]:\n",
    "            print(\" {} - {:12s} {:.2f}%\".format(class_id, name, y_proba *100))\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af32f4c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PrefetchDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1048/1370011353.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'PrefetchDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "train_set['label']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
