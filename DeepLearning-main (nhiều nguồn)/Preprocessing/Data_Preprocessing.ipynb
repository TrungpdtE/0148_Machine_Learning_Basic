{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a4b174-b1d2-4f58-8320-c0d5a4dffbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ddea323-78a6-40a0-9a66-25805e4b209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.range(10)\n",
    "\n",
    "# this dataset is entirely in the ram\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef9e626d-2b12-4af5-a92d-d84641b517e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# chaining transformation -> repeat 3 times; batch of 7\n",
    "\n",
    "dataset = dataset.repeat(3).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be27f2f7-2232-42da-9151-57fab12cf50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
      "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# map\n",
    "\n",
    "dataset = dataset.map(lambda x: x * 2)\n",
    "\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1ddef07-2a3c-49fd-9c7a-3f3bd62a7b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 2 3 6 7 9 4], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 0 1 1 8 6 5], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 8 7 1 2 3 0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 4 2 7 8 9 9], shape=(7,), dtype=int64)\n",
      "tf.Tensor([3 6], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# shuffle with buffer -> buffer\n",
    "\n",
    "dataset = tf.data.Dataset.range(10).repeat(3) # 0 to 9, three times\n",
    "dataset = dataset.shuffle(buffer_size=5, seed=42).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c97df7-4de8-4f88-96f2-d9020bab10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths interleaving\n",
    "\n",
    "n_readers = 5\n",
    "dataset = filepath_dataset.interleave(\n",
    "                                        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "                                        cycle_length=n_readers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ec5353-3f03-4ca0-a94d-7056d61d596c",
   "metadata": {},
   "source": [
    "# Preprocessing input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feae2aeb-4ed4-4287-97b4-4cbf8ba00276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "\n",
    "means = np.mean(X_train, axis=0, keepdims=True)\n",
    "stds = np.std(X_train, axis=0, keepdims=True)\n",
    "eps = keras.backend.epsilon()\n",
    "model = keras.models.Sequential([keras.layers.Lambda(lambda inputs: (inputs - means) / (stds + eps)),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f42f43-85ed-4fac-9c1d-3dae6acbc693",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "        _ p ( _ p , , p )\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df28ea30-06ac-4279-8a82-3a1e355fe7dc",
   "metadata": {},
   "source": [
    "### Categorical -> One hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "652f558d-6ff4-42ee-8ffc-baa36c51ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary -> list of all possible categories\n",
    "\n",
    "vocab = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]\n",
    "\n",
    "# tensor with corresponding indices\n",
    "indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "\n",
    "# intializer of lookup table\n",
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "# assign to one of the buckets if not in vocab based on hash value\n",
    "num_oov_buckets = 2\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "674b955b-3512-45d4-b4fe-3a8caad0df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate one hot encodings \n",
    "\n",
    "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
    "cat_indices = table.lookup(categories)\n",
    "cat_indices\n",
    "cat_one_hot = tf.one_hot(cat_indices, depth=len(vocab) + num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cc7ccf4-869f-47dc-8180-7c3c66904c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 7), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2567a8bc-c913-42b4-be71-aea59f3bff49",
   "metadata": {},
   "source": [
    "# Using Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de575e87-1378-40a4-8126-9349515232b7",
   "metadata": {},
   "source": [
    "### Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4207f948-c3f0-4941-8ff6-be21563f9b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(7, 2) dtype=float32, numpy=\n",
       "array([[0.3420329 , 0.4006294 ],\n",
       "       [0.7949134 , 0.04551959],\n",
       "       [0.4818431 , 0.00312006],\n",
       "       [0.33208966, 0.08944726],\n",
       "       [0.896736  , 0.23530567],\n",
       "       [0.2511623 , 0.41745567],\n",
       "       [0.46479917, 0.27548933]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "embedding_dim = 2\n",
    "# innitialize randomly => Embedding dimension is a hyperparameter\n",
    "embed_init = tf.random.uniform([len(vocab) + num_oov_buckets,embedding_dim])\n",
    "embedding_matrix = tf.Variable(embed_init)\n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81961c5-6b9f-4093-be1e-171d9c553d32",
   "metadata": {},
   "source": [
    "### encode with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f9ccd5a-4a44-42f1-a123-3732d5058bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0.33208966, 0.08944726],\n",
       "       [0.2511623 , 0.41745567],\n",
       "       [0.7949134 , 0.04551959],\n",
       "       [0.7949134 , 0.04551959]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
    "cat_indices = table.lookup(categories)\n",
    "tf.nn.embedding_lookup(embedding_matrix, cat_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c6b0f4-54d8-4f00-9aa0-5cbbf9d5dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_inputs = keras.layers.Input(shape=[8])\n",
    "categories = keras.layers.Input(shape=[], dtype=tf.string)\n",
    "cat_indices = keras.layers.Lambda(lambda cats: table.lookup(cats))(categories)\n",
    "cat_embed = keras.layers.Embedding(input_dim=6, output_dim=2)(cat_indices)\n",
    "encoded_inputs = keras.layers.concatenate([regular_inputs, cat_embed])\n",
    "outputs = keras.layers.Dense(1)(encoded_inputs)\n",
    "model = keras.models.Model(inputs=[regular_inputs, categories],\n",
    "outputs=[outputs])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b945fd-22b5-4f07-baef-6b5acbb829d2",
   "metadata": {},
   "source": [
    "# Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb61219e-c734-4cd2-852e-b1b7bddaef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization = keras.layers.Normalization()\n",
    "discretization = keras.layers.Discretization([...])\n",
    "pipeline = keras.layers.PreprocessingStage([normalization,\n",
    "discretization])\n",
    "pipeline.adapt(data_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4900dc92-2f12-4832-a4fa-026f55d6ae88",
   "metadata": {},
   "source": [
    "# Tf Transform\n",
    "If preprocessing is expensive, handlig it before training is better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324ac994-9fc6-4b20-89c2-c39afbea6872",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization = keras.layers.Normalization()\n",
    "discretization = keras.layers.Discretization([...])\n",
    "pipeline = keras.layers.PreprocessingStage([normalization,\n",
    "discretization])\n",
    "pipeline.adapt(data_sample)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
