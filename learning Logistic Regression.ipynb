{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2e52a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, epochs=100):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        \"\"\"Sigmoid activation function.\"\"\"\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def compute_loss(self, y, predictions):\n",
    "        \"\"\"Binary cross-entropy loss function.\"\"\"\n",
    "        num_samples = len(y)\n",
    "        loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
    "        return loss\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the logistic regression model.\"\"\"\n",
    "        num_samples, num_features = X.shape\n",
    "        self.weights = np.zeros(num_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            # Linear model\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            # Apply sigmoid function\n",
    "            predictions = self.sigmoid(linear_model)\n",
    "\n",
    "            # Compute gradients\n",
    "            dw = (1 / num_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1 / num_samples) * np.sum(predictions - y)\n",
    "\n",
    "            # Update weights and bias\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "            \n",
    "             # Print loss and weights for each epoch\n",
    "            loss = self.compute_loss(y, predictions)\n",
    "            print(f\"Epoch {epoch + 1}/{self.epochs} - Loss: {loss:.4f} - Weights: {self.weights} - Bias: {self.bias:.4f}\")\n",
    "\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict binary labels for input samples.\"\"\"\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        probabilities = self.sigmoid(linear_model)\n",
    "        return [1 if p > 0.5 else 0 for p in probabilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e142f677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37454012 0.95071431]\n",
      " [0.73199394 0.59865848]\n",
      " [0.15601864 0.15599452]\n",
      " [0.05808361 0.86617615]\n",
      " [0.60111501 0.70807258]]\n",
      "[1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic dataset\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 2)  # 100 samples, 2 features\n",
    "y = (X[:, 0] + X[:, 1] > 1).astype(int)  # Label: 1 if sum of features > 1, else 0\n",
    "print(X[:5])\n",
    "print(y[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e054fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 - Loss: 0.6931 - Weights: [0.0070345  0.00296785] - Bias: -0.0070\n",
      "Epoch 2/1000 - Loss: 0.6921 - Weights: [0.0140791  0.00595672] - Bias: -0.0139\n",
      "Epoch 3/1000 - Loss: 0.6910 - Weights: [0.02113295 0.00896572] - Bias: -0.0208\n",
      "Epoch 4/1000 - Loss: 0.6899 - Weights: [0.02819521 0.011994  ] - Bias: -0.0277\n",
      "Epoch 5/1000 - Loss: 0.6889 - Weights: [0.03526511 0.01504073] - Bias: -0.0345\n",
      "Epoch 6/1000 - Loss: 0.6878 - Weights: [0.04234188 0.01810514] - Bias: -0.0412\n",
      "Epoch 7/1000 - Loss: 0.6868 - Weights: [0.04942478 0.02118644] - Bias: -0.0479\n",
      "Epoch 8/1000 - Loss: 0.6857 - Weights: [0.05651312 0.02428392] - Bias: -0.0546\n",
      "Epoch 9/1000 - Loss: 0.6847 - Weights: [0.06360622 0.02739687] - Bias: -0.0612\n",
      "Epoch 10/1000 - Loss: 0.6837 - Weights: [0.07070342 0.0305246 ] - Bias: -0.0678\n",
      "Epoch 11/1000 - Loss: 0.6826 - Weights: [0.07780411 0.03366646] - Bias: -0.0743\n",
      "Epoch 12/1000 - Loss: 0.6816 - Weights: [0.08490768 0.03682183] - Bias: -0.0808\n",
      "Epoch 13/1000 - Loss: 0.6806 - Weights: [0.09201355 0.03999009] - Bias: -0.0872\n",
      "Epoch 14/1000 - Loss: 0.6796 - Weights: [0.09912118 0.04317066] - Bias: -0.0936\n",
      "Epoch 15/1000 - Loss: 0.6785 - Weights: [0.10623002 0.04636298] - Bias: -0.1000\n",
      "Epoch 16/1000 - Loss: 0.6775 - Weights: [0.11333957 0.04956651] - Bias: -0.1064\n",
      "Epoch 17/1000 - Loss: 0.6765 - Weights: [0.12044934 0.05278073] - Bias: -0.1127\n",
      "Epoch 18/1000 - Loss: 0.6755 - Weights: [0.12755884 0.05600514] - Bias: -0.1189\n",
      "Epoch 19/1000 - Loss: 0.6745 - Weights: [0.13466763 0.05923925] - Bias: -0.1252\n",
      "Epoch 20/1000 - Loss: 0.6735 - Weights: [0.14177527 0.06248259] - Bias: -0.1314\n",
      "Epoch 21/1000 - Loss: 0.6725 - Weights: [0.14888134 0.06573473] - Bias: -0.1376\n",
      "Epoch 22/1000 - Loss: 0.6715 - Weights: [0.15598544 0.06899523] - Bias: -0.1437\n",
      "Epoch 23/1000 - Loss: 0.6705 - Weights: [0.16308718 0.07226368] - Bias: -0.1498\n",
      "Epoch 24/1000 - Loss: 0.6696 - Weights: [0.17018619 0.07553967] - Bias: -0.1559\n",
      "Epoch 25/1000 - Loss: 0.6686 - Weights: [0.17728212 0.07882283] - Bias: -0.1620\n",
      "Epoch 26/1000 - Loss: 0.6676 - Weights: [0.18437462 0.08211278] - Bias: -0.1681\n",
      "Epoch 27/1000 - Loss: 0.6666 - Weights: [0.19146336 0.08540917] - Bias: -0.1741\n",
      "Epoch 28/1000 - Loss: 0.6656 - Weights: [0.19854804 0.08871165] - Bias: -0.1801\n",
      "Epoch 29/1000 - Loss: 0.6647 - Weights: [0.20562834 0.0920199 ] - Bias: -0.1860\n",
      "Epoch 30/1000 - Loss: 0.6637 - Weights: [0.21270399 0.0953336 ] - Bias: -0.1920\n",
      "Epoch 31/1000 - Loss: 0.6627 - Weights: [0.21977469 0.09865244] - Bias: -0.1979\n",
      "Epoch 32/1000 - Loss: 0.6618 - Weights: [0.22684019 0.10197613] - Bias: -0.2038\n",
      "Epoch 33/1000 - Loss: 0.6608 - Weights: [0.23390022 0.10530439] - Bias: -0.2097\n",
      "Epoch 34/1000 - Loss: 0.6599 - Weights: [0.24095455 0.10863693] - Bias: -0.2155\n",
      "Epoch 35/1000 - Loss: 0.6589 - Weights: [0.24800293 0.11197351] - Bias: -0.2214\n",
      "Epoch 36/1000 - Loss: 0.6580 - Weights: [0.25504514 0.11531387] - Bias: -0.2272\n",
      "Epoch 37/1000 - Loss: 0.6570 - Weights: [0.26208097 0.11865777] - Bias: -0.2330\n",
      "Epoch 38/1000 - Loss: 0.6561 - Weights: [0.26911021 0.12200497] - Bias: -0.2387\n",
      "Epoch 39/1000 - Loss: 0.6552 - Weights: [0.27613266 0.12535524] - Bias: -0.2445\n",
      "Epoch 40/1000 - Loss: 0.6542 - Weights: [0.28314814 0.12870838] - Bias: -0.2502\n",
      "Epoch 41/1000 - Loss: 0.6533 - Weights: [0.29015645 0.13206416] - Bias: -0.2559\n",
      "Epoch 42/1000 - Loss: 0.6524 - Weights: [0.29715742 0.13542241] - Bias: -0.2617\n",
      "Epoch 43/1000 - Loss: 0.6514 - Weights: [0.3041509  0.13878291] - Bias: -0.2673\n",
      "Epoch 44/1000 - Loss: 0.6505 - Weights: [0.31113671 0.14214548] - Bias: -0.2730\n",
      "Epoch 45/1000 - Loss: 0.6496 - Weights: [0.31811471 0.14550995] - Bias: -0.2787\n",
      "Epoch 46/1000 - Loss: 0.6487 - Weights: [0.32508475 0.14887614] - Bias: -0.2843\n",
      "Epoch 47/1000 - Loss: 0.6477 - Weights: [0.33204669 0.15224389] - Bias: -0.2899\n",
      "Epoch 48/1000 - Loss: 0.6468 - Weights: [0.3390004  0.15561304] - Bias: -0.2955\n",
      "Epoch 49/1000 - Loss: 0.6459 - Weights: [0.34594575 0.15898343] - Bias: -0.3011\n",
      "Epoch 50/1000 - Loss: 0.6450 - Weights: [0.35288262 0.16235492] - Bias: -0.3067\n",
      "Epoch 51/1000 - Loss: 0.6441 - Weights: [0.3598109  0.16572736] - Bias: -0.3122\n",
      "Epoch 52/1000 - Loss: 0.6432 - Weights: [0.36673047 0.16910063] - Bias: -0.3178\n",
      "Epoch 53/1000 - Loss: 0.6423 - Weights: [0.37364122 0.17247458] - Bias: -0.3233\n",
      "Epoch 54/1000 - Loss: 0.6414 - Weights: [0.38054307 0.1758491 ] - Bias: -0.3288\n",
      "Epoch 55/1000 - Loss: 0.6405 - Weights: [0.3874359  0.17922405] - Bias: -0.3343\n",
      "Epoch 56/1000 - Loss: 0.6396 - Weights: [0.39431963 0.18259933] - Bias: -0.3398\n",
      "Epoch 57/1000 - Loss: 0.6387 - Weights: [0.40119418 0.18597482] - Bias: -0.3453\n",
      "Epoch 58/1000 - Loss: 0.6379 - Weights: [0.40805945 0.18935041] - Bias: -0.3507\n",
      "Epoch 59/1000 - Loss: 0.6370 - Weights: [0.41491537 0.192726  ] - Bias: -0.3562\n",
      "Epoch 60/1000 - Loss: 0.6361 - Weights: [0.42176188 0.19610149] - Bias: -0.3616\n",
      "Epoch 61/1000 - Loss: 0.6352 - Weights: [0.42859888 0.19947678] - Bias: -0.3671\n",
      "Epoch 62/1000 - Loss: 0.6343 - Weights: [0.43542632 0.20285178] - Bias: -0.3725\n",
      "Epoch 63/1000 - Loss: 0.6335 - Weights: [0.44224414 0.20622639] - Bias: -0.3779\n",
      "Epoch 64/1000 - Loss: 0.6326 - Weights: [0.44905227 0.20960055] - Bias: -0.3833\n",
      "Epoch 65/1000 - Loss: 0.6317 - Weights: [0.45585065 0.21297415] - Bias: -0.3886\n",
      "Epoch 66/1000 - Loss: 0.6309 - Weights: [0.46263923 0.21634713] - Bias: -0.3940\n",
      "Epoch 67/1000 - Loss: 0.6300 - Weights: [0.46941797 0.2197194 ] - Bias: -0.3994\n",
      "Epoch 68/1000 - Loss: 0.6291 - Weights: [0.4761868 0.2230909] - Bias: -0.4047\n",
      "Epoch 69/1000 - Loss: 0.6283 - Weights: [0.48294569 0.22646154] - Bias: -0.4100\n",
      "Epoch 70/1000 - Loss: 0.6274 - Weights: [0.48969459 0.22983128] - Bias: -0.4154\n",
      "Epoch 71/1000 - Loss: 0.6266 - Weights: [0.49643346 0.23320003] - Bias: -0.4207\n",
      "Epoch 72/1000 - Loss: 0.6257 - Weights: [0.50316227 0.23656773] - Bias: -0.4260\n",
      "Epoch 73/1000 - Loss: 0.6249 - Weights: [0.50988097 0.23993434] - Bias: -0.4313\n",
      "Epoch 74/1000 - Loss: 0.6240 - Weights: [0.51658953 0.24329978] - Bias: -0.4366\n",
      "Epoch 75/1000 - Loss: 0.6232 - Weights: [0.52328793 0.24666401] - Bias: -0.4418\n",
      "Epoch 76/1000 - Loss: 0.6224 - Weights: [0.52997614 0.25002696] - Bias: -0.4471\n",
      "Epoch 77/1000 - Loss: 0.6215 - Weights: [0.53665411 0.25338859] - Bias: -0.4523\n",
      "Epoch 78/1000 - Loss: 0.6207 - Weights: [0.54332184 0.25674885] - Bias: -0.4576\n",
      "Epoch 79/1000 - Loss: 0.6199 - Weights: [0.5499793  0.26010769] - Bias: -0.4628\n",
      "Epoch 80/1000 - Loss: 0.6190 - Weights: [0.55662647 0.26346506] - Bias: -0.4680\n",
      "Epoch 81/1000 - Loss: 0.6182 - Weights: [0.56326332 0.26682093] - Bias: -0.4732\n",
      "Epoch 82/1000 - Loss: 0.6174 - Weights: [0.56988983 0.27017524] - Bias: -0.4785\n",
      "Epoch 83/1000 - Loss: 0.6166 - Weights: [0.57650601 0.27352796] - Bias: -0.4836\n",
      "Epoch 84/1000 - Loss: 0.6157 - Weights: [0.58311181 0.27687905] - Bias: -0.4888\n",
      "Epoch 85/1000 - Loss: 0.6149 - Weights: [0.58970724 0.28022847] - Bias: -0.4940\n",
      "Epoch 86/1000 - Loss: 0.6141 - Weights: [0.59629229 0.28357619] - Bias: -0.4992\n",
      "Epoch 87/1000 - Loss: 0.6133 - Weights: [0.60286693 0.28692217] - Bias: -0.5043\n",
      "Epoch 88/1000 - Loss: 0.6125 - Weights: [0.60943116 0.29026638] - Bias: -0.5095\n",
      "Epoch 89/1000 - Loss: 0.6117 - Weights: [0.61598498 0.29360878] - Bias: -0.5146\n",
      "Epoch 90/1000 - Loss: 0.6109 - Weights: [0.62252837 0.29694935] - Bias: -0.5198\n",
      "Epoch 91/1000 - Loss: 0.6101 - Weights: [0.62906134 0.30028805] - Bias: -0.5249\n",
      "Epoch 92/1000 - Loss: 0.6093 - Weights: [0.63558387 0.30362487] - Bias: -0.5300\n",
      "Epoch 93/1000 - Loss: 0.6085 - Weights: [0.64209596 0.30695976] - Bias: -0.5351\n",
      "Epoch 94/1000 - Loss: 0.6077 - Weights: [0.64859761 0.31029271] - Bias: -0.5402\n",
      "Epoch 95/1000 - Loss: 0.6069 - Weights: [0.65508882 0.31362369] - Bias: -0.5453\n",
      "Epoch 96/1000 - Loss: 0.6061 - Weights: [0.66156959 0.31695267] - Bias: -0.5504\n",
      "Epoch 97/1000 - Loss: 0.6053 - Weights: [0.66803992 0.32027964] - Bias: -0.5554\n",
      "Epoch 98/1000 - Loss: 0.6045 - Weights: [0.6744998  0.32360458] - Bias: -0.5605\n",
      "Epoch 99/1000 - Loss: 0.6037 - Weights: [0.68094925 0.32692745] - Bias: -0.5656\n",
      "Epoch 100/1000 - Loss: 0.6029 - Weights: [0.68738827 0.33024824] - Bias: -0.5706\n",
      "Epoch 101/1000 - Loss: 0.6022 - Weights: [0.69381685 0.33356693] - Bias: -0.5757\n",
      "Epoch 102/1000 - Loss: 0.6014 - Weights: [0.700235   0.33688351] - Bias: -0.5807\n",
      "Epoch 103/1000 - Loss: 0.6006 - Weights: [0.70664273 0.34019795] - Bias: -0.5857\n",
      "Epoch 104/1000 - Loss: 0.5998 - Weights: [0.71304005 0.34351024] - Bias: -0.5907\n",
      "Epoch 105/1000 - Loss: 0.5991 - Weights: [0.71942696 0.34682036] - Bias: -0.5958\n",
      "Epoch 106/1000 - Loss: 0.5983 - Weights: [0.72580346 0.3501283 ] - Bias: -0.6008\n",
      "Epoch 107/1000 - Loss: 0.5975 - Weights: [0.73216957 0.35343404] - Bias: -0.6058\n",
      "Epoch 108/1000 - Loss: 0.5968 - Weights: [0.7385253  0.35673756] - Bias: -0.6107\n",
      "Epoch 109/1000 - Loss: 0.5960 - Weights: [0.74487065 0.36003886] - Bias: -0.6157\n",
      "Epoch 110/1000 - Loss: 0.5953 - Weights: [0.75120563 0.36333791] - Bias: -0.6207\n",
      "Epoch 111/1000 - Loss: 0.5945 - Weights: [0.75753026 0.36663472] - Bias: -0.6257\n",
      "Epoch 112/1000 - Loss: 0.5937 - Weights: [0.76384453 0.36992926] - Bias: -0.6306\n",
      "Epoch 113/1000 - Loss: 0.5930 - Weights: [0.77014848 0.37322152] - Bias: -0.6356\n",
      "Epoch 114/1000 - Loss: 0.5922 - Weights: [0.7764421 0.3765115] - Bias: -0.6405\n",
      "Epoch 115/1000 - Loss: 0.5915 - Weights: [0.78272541 0.37979918] - Bias: -0.6454\n",
      "Epoch 116/1000 - Loss: 0.5907 - Weights: [0.78899841 0.38308456] - Bias: -0.6504\n",
      "Epoch 117/1000 - Loss: 0.5900 - Weights: [0.79526114 0.38636762] - Bias: -0.6553\n",
      "Epoch 118/1000 - Loss: 0.5893 - Weights: [0.80151358 0.38964835] - Bias: -0.6602\n",
      "Epoch 119/1000 - Loss: 0.5885 - Weights: [0.80775577 0.39292675] - Bias: -0.6651\n",
      "Epoch 120/1000 - Loss: 0.5878 - Weights: [0.81398772 0.39620281] - Bias: -0.6700\n",
      "Epoch 121/1000 - Loss: 0.5871 - Weights: [0.82020943 0.39947651] - Bias: -0.6749\n",
      "Epoch 122/1000 - Loss: 0.5863 - Weights: [0.82642092 0.40274786] - Bias: -0.6798\n",
      "Epoch 123/1000 - Loss: 0.5856 - Weights: [0.83262222 0.40601685] - Bias: -0.6847\n",
      "Epoch 124/1000 - Loss: 0.5849 - Weights: [0.83881332 0.40928346] - Bias: -0.6895\n",
      "Epoch 125/1000 - Loss: 0.5841 - Weights: [0.84499426 0.4125477 ] - Bias: -0.6944\n",
      "Epoch 126/1000 - Loss: 0.5834 - Weights: [0.85116504 0.41580956] - Bias: -0.6993\n",
      "Epoch 127/1000 - Loss: 0.5827 - Weights: [0.85732568 0.41906902] - Bias: -0.7041\n",
      "Epoch 128/1000 - Loss: 0.5820 - Weights: [0.8634762  0.42232609] - Bias: -0.7089\n",
      "Epoch 129/1000 - Loss: 0.5812 - Weights: [0.86961661 0.42558077] - Bias: -0.7138\n",
      "Epoch 130/1000 - Loss: 0.5805 - Weights: [0.87574694 0.42883303] - Bias: -0.7186\n",
      "Epoch 131/1000 - Loss: 0.5798 - Weights: [0.88186719 0.43208289] - Bias: -0.7234\n",
      "Epoch 132/1000 - Loss: 0.5791 - Weights: [0.88797738 0.43533034] - Bias: -0.7282\n",
      "Epoch 133/1000 - Loss: 0.5784 - Weights: [0.89407754 0.43857537] - Bias: -0.7331\n",
      "Epoch 134/1000 - Loss: 0.5777 - Weights: [0.90016768 0.44181798] - Bias: -0.7379\n",
      "Epoch 135/1000 - Loss: 0.5770 - Weights: [0.90624781 0.44505816] - Bias: -0.7427\n",
      "Epoch 136/1000 - Loss: 0.5763 - Weights: [0.91231797 0.44829592] - Bias: -0.7474\n",
      "Epoch 137/1000 - Loss: 0.5756 - Weights: [0.91837815 0.45153125] - Bias: -0.7522\n",
      "Epoch 138/1000 - Loss: 0.5749 - Weights: [0.92442839 0.45476414] - Bias: -0.7570\n",
      "Epoch 139/1000 - Loss: 0.5742 - Weights: [0.9304687 0.4579946] - Bias: -0.7618\n",
      "Epoch 140/1000 - Loss: 0.5735 - Weights: [0.9364991  0.46122262] - Bias: -0.7665\n",
      "Epoch 141/1000 - Loss: 0.5728 - Weights: [0.9425196 0.4644482] - Bias: -0.7713\n",
      "Epoch 142/1000 - Loss: 0.5721 - Weights: [0.94853023 0.46767134] - Bias: -0.7760\n",
      "Epoch 143/1000 - Loss: 0.5714 - Weights: [0.95453101 0.47089203] - Bias: -0.7808\n",
      "Epoch 144/1000 - Loss: 0.5707 - Weights: [0.96052196 0.47411027] - Bias: -0.7855\n",
      "Epoch 145/1000 - Loss: 0.5700 - Weights: [0.96650309 0.47732607] - Bias: -0.7902\n",
      "Epoch 146/1000 - Loss: 0.5693 - Weights: [0.97247442 0.48053942] - Bias: -0.7950\n",
      "Epoch 147/1000 - Loss: 0.5687 - Weights: [0.97843597 0.48375031] - Bias: -0.7997\n",
      "Epoch 148/1000 - Loss: 0.5680 - Weights: [0.98438777 0.48695876] - Bias: -0.8044\n",
      "Epoch 149/1000 - Loss: 0.5673 - Weights: [0.99032983 0.49016475] - Bias: -0.8091\n",
      "Epoch 150/1000 - Loss: 0.5666 - Weights: [0.99626218 0.49336828] - Bias: -0.8138\n",
      "Epoch 151/1000 - Loss: 0.5660 - Weights: [1.00218482 0.49656937] - Bias: -0.8185\n",
      "Epoch 152/1000 - Loss: 0.5653 - Weights: [1.00809779 0.499768  ] - Bias: -0.8231\n",
      "Epoch 153/1000 - Loss: 0.5646 - Weights: [1.0140011  0.50296417] - Bias: -0.8278\n",
      "Epoch 154/1000 - Loss: 0.5639 - Weights: [1.01989477 0.50615788] - Bias: -0.8325\n",
      "Epoch 155/1000 - Loss: 0.5633 - Weights: [1.02577882 0.50934914] - Bias: -0.8372\n",
      "Epoch 156/1000 - Loss: 0.5626 - Weights: [1.03165327 0.51253795] - Bias: -0.8418\n",
      "Epoch 157/1000 - Loss: 0.5619 - Weights: [1.03751815 0.5157243 ] - Bias: -0.8465\n",
      "Epoch 158/1000 - Loss: 0.5613 - Weights: [1.04337347 0.51890819] - Bias: -0.8511\n",
      "Epoch 159/1000 - Loss: 0.5606 - Weights: [1.04921925 0.52208962] - Bias: -0.8558\n",
      "Epoch 160/1000 - Loss: 0.5600 - Weights: [1.05505551 0.5252686 ] - Bias: -0.8604\n",
      "Epoch 161/1000 - Loss: 0.5593 - Weights: [1.06088228 0.52844512] - Bias: -0.8650\n",
      "Epoch 162/1000 - Loss: 0.5587 - Weights: [1.06669957 0.53161919] - Bias: -0.8696\n",
      "Epoch 163/1000 - Loss: 0.5580 - Weights: [1.07250741 0.53479081] - Bias: -0.8742\n",
      "Epoch 164/1000 - Loss: 0.5574 - Weights: [1.07830581 0.53795997] - Bias: -0.8789\n",
      "Epoch 165/1000 - Loss: 0.5567 - Weights: [1.08409479 0.54112667] - Bias: -0.8835\n",
      "Epoch 166/1000 - Loss: 0.5561 - Weights: [1.08987438 0.54429093] - Bias: -0.8880\n",
      "Epoch 167/1000 - Loss: 0.5554 - Weights: [1.0956446  0.54745273] - Bias: -0.8926\n",
      "Epoch 168/1000 - Loss: 0.5548 - Weights: [1.10140546 0.55061208] - Bias: -0.8972\n",
      "Epoch 169/1000 - Loss: 0.5541 - Weights: [1.10715699 0.55376898] - Bias: -0.9018\n",
      "Epoch 170/1000 - Loss: 0.5535 - Weights: [1.11289921 0.55692344] - Bias: -0.9064\n",
      "Epoch 171/1000 - Loss: 0.5529 - Weights: [1.11863214 0.56007544] - Bias: -0.9109\n",
      "Epoch 172/1000 - Loss: 0.5522 - Weights: [1.1243558 0.563225 ] - Bias: -0.9155\n",
      "Epoch 173/1000 - Loss: 0.5516 - Weights: [1.1300702  0.56637211] - Bias: -0.9200\n",
      "Epoch 174/1000 - Loss: 0.5510 - Weights: [1.13577538 0.56951678] - Bias: -0.9246\n",
      "Epoch 175/1000 - Loss: 0.5503 - Weights: [1.14147135 0.57265901] - Bias: -0.9291\n",
      "Epoch 176/1000 - Loss: 0.5497 - Weights: [1.14715813 0.5757988 ] - Bias: -0.9337\n",
      "Epoch 177/1000 - Loss: 0.5491 - Weights: [1.15283574 0.57893614] - Bias: -0.9382\n",
      "Epoch 178/1000 - Loss: 0.5484 - Weights: [1.15850421 0.58207105] - Bias: -0.9427\n",
      "Epoch 179/1000 - Loss: 0.5478 - Weights: [1.16416354 0.58520352] - Bias: -0.9472\n",
      "Epoch 180/1000 - Loss: 0.5472 - Weights: [1.16981378 0.58833356] - Bias: -0.9517\n",
      "Epoch 181/1000 - Loss: 0.5466 - Weights: [1.17545492 0.59146116] - Bias: -0.9562\n",
      "Epoch 182/1000 - Loss: 0.5460 - Weights: [1.18108701 0.59458633] - Bias: -0.9607\n",
      "Epoch 183/1000 - Loss: 0.5453 - Weights: [1.18671005 0.59770907] - Bias: -0.9652\n",
      "Epoch 184/1000 - Loss: 0.5447 - Weights: [1.19232406 0.60082938] - Bias: -0.9697\n",
      "Epoch 185/1000 - Loss: 0.5441 - Weights: [1.19792907 0.60394727] - Bias: -0.9742\n",
      "Epoch 186/1000 - Loss: 0.5435 - Weights: [1.20352511 0.60706273] - Bias: -0.9787\n",
      "Epoch 187/1000 - Loss: 0.5429 - Weights: [1.20911217 0.61017576] - Bias: -0.9831\n",
      "Epoch 188/1000 - Loss: 0.5423 - Weights: [1.2146903  0.61328638] - Bias: -0.9876\n",
      "Epoch 189/1000 - Loss: 0.5417 - Weights: [1.22025951 0.61639458] - Bias: -0.9921\n",
      "Epoch 190/1000 - Loss: 0.5411 - Weights: [1.22581982 0.61950036] - Bias: -0.9965\n",
      "Epoch 191/1000 - Loss: 0.5405 - Weights: [1.23137125 0.62260372] - Bias: -1.0010\n",
      "Epoch 192/1000 - Loss: 0.5399 - Weights: [1.23691381 0.62570467] - Bias: -1.0054\n",
      "Epoch 193/1000 - Loss: 0.5393 - Weights: [1.24244754 0.62880322] - Bias: -1.0098\n",
      "Epoch 194/1000 - Loss: 0.5387 - Weights: [1.24797246 0.63189935] - Bias: -1.0143\n",
      "Epoch 195/1000 - Loss: 0.5381 - Weights: [1.25348857 0.63499307] - Bias: -1.0187\n",
      "Epoch 196/1000 - Loss: 0.5375 - Weights: [1.25899591 0.63808439] - Bias: -1.0231\n",
      "Epoch 197/1000 - Loss: 0.5369 - Weights: [1.26449449 0.64117331] - Bias: -1.0275\n",
      "Epoch 198/1000 - Loss: 0.5363 - Weights: [1.26998433 0.64425983] - Bias: -1.0319\n",
      "Epoch 199/1000 - Loss: 0.5357 - Weights: [1.27546546 0.64734394] - Bias: -1.0363\n",
      "Epoch 200/1000 - Loss: 0.5351 - Weights: [1.28093789 0.65042567] - Bias: -1.0407\n",
      "Epoch 201/1000 - Loss: 0.5345 - Weights: [1.28640164 0.653505  ] - Bias: -1.0451\n",
      "Epoch 202/1000 - Loss: 0.5339 - Weights: [1.29185674 0.65658193] - Bias: -1.0495\n",
      "Epoch 203/1000 - Loss: 0.5334 - Weights: [1.29730321 0.65965648] - Bias: -1.0538\n",
      "Epoch 204/1000 - Loss: 0.5328 - Weights: [1.30274105 0.66272865] - Bias: -1.0582\n",
      "Epoch 205/1000 - Loss: 0.5322 - Weights: [1.30817031 0.66579842] - Bias: -1.0626\n",
      "Epoch 206/1000 - Loss: 0.5316 - Weights: [1.31359099 0.66886582] - Bias: -1.0669\n",
      "Epoch 207/1000 - Loss: 0.5310 - Weights: [1.31900311 0.67193083] - Bias: -1.0713\n",
      "Epoch 208/1000 - Loss: 0.5305 - Weights: [1.3244067  0.67499347] - Bias: -1.0756\n",
      "Epoch 209/1000 - Loss: 0.5299 - Weights: [1.32980177 0.67805374] - Bias: -1.0800\n",
      "Epoch 210/1000 - Loss: 0.5293 - Weights: [1.33518835 0.68111163] - Bias: -1.0843\n",
      "Epoch 211/1000 - Loss: 0.5287 - Weights: [1.34056645 0.68416715] - Bias: -1.0886\n",
      "Epoch 212/1000 - Loss: 0.5282 - Weights: [1.3459361 0.6872203] - Bias: -1.0930\n",
      "Epoch 213/1000 - Loss: 0.5276 - Weights: [1.35129732 0.69027109] - Bias: -1.0973\n",
      "Epoch 214/1000 - Loss: 0.5270 - Weights: [1.35665011 0.69331951] - Bias: -1.1016\n",
      "Epoch 215/1000 - Loss: 0.5265 - Weights: [1.36199452 0.69636558] - Bias: -1.1059\n",
      "Epoch 216/1000 - Loss: 0.5259 - Weights: [1.36733054 0.69940929] - Bias: -1.1102\n",
      "Epoch 217/1000 - Loss: 0.5253 - Weights: [1.37265821 0.70245064] - Bias: -1.1145\n",
      "Epoch 218/1000 - Loss: 0.5248 - Weights: [1.37797755 0.70548964] - Bias: -1.1188\n",
      "Epoch 219/1000 - Loss: 0.5242 - Weights: [1.38328857 0.70852629] - Bias: -1.1231\n",
      "Epoch 220/1000 - Loss: 0.5237 - Weights: [1.38859129 0.71156059] - Bias: -1.1274\n",
      "Epoch 221/1000 - Loss: 0.5231 - Weights: [1.39388573 0.71459255] - Bias: -1.1317\n",
      "Epoch 222/1000 - Loss: 0.5226 - Weights: [1.39917192 0.71762216] - Bias: -1.1359\n",
      "Epoch 223/1000 - Loss: 0.5220 - Weights: [1.40444986 0.72064944] - Bias: -1.1402\n",
      "Epoch 224/1000 - Loss: 0.5214 - Weights: [1.40971959 0.72367438] - Bias: -1.1444\n",
      "Epoch 225/1000 - Loss: 0.5209 - Weights: [1.41498112 0.72669698] - Bias: -1.1487\n",
      "Epoch 226/1000 - Loss: 0.5203 - Weights: [1.42023447 0.72971725] - Bias: -1.1530\n",
      "Epoch 227/1000 - Loss: 0.5198 - Weights: [1.42547966 0.73273519] - Bias: -1.1572\n",
      "Epoch 228/1000 - Loss: 0.5193 - Weights: [1.4307167  0.73575081] - Bias: -1.1614\n",
      "Epoch 229/1000 - Loss: 0.5187 - Weights: [1.43594563 0.7387641 ] - Bias: -1.1657\n",
      "Epoch 230/1000 - Loss: 0.5182 - Weights: [1.44116645 0.74177507] - Bias: -1.1699\n",
      "Epoch 231/1000 - Loss: 0.5176 - Weights: [1.44637919 0.74478372] - Bias: -1.1741\n",
      "Epoch 232/1000 - Loss: 0.5171 - Weights: [1.45158386 0.74779005] - Bias: -1.1783\n",
      "Epoch 233/1000 - Loss: 0.5165 - Weights: [1.45678049 0.75079407] - Bias: -1.1825\n",
      "Epoch 234/1000 - Loss: 0.5160 - Weights: [1.46196909 0.75379578] - Bias: -1.1867\n",
      "Epoch 235/1000 - Loss: 0.5155 - Weights: [1.46714968 0.75679519] - Bias: -1.1909\n",
      "Epoch 236/1000 - Loss: 0.5149 - Weights: [1.47232229 0.75979228] - Bias: -1.1951\n",
      "Epoch 237/1000 - Loss: 0.5144 - Weights: [1.47748693 0.76278708] - Bias: -1.1993\n",
      "Epoch 238/1000 - Loss: 0.5139 - Weights: [1.48264361 0.76577957] - Bias: -1.2035\n",
      "Epoch 239/1000 - Loss: 0.5133 - Weights: [1.48779237 0.76876977] - Bias: -1.2077\n",
      "Epoch 240/1000 - Loss: 0.5128 - Weights: [1.49293321 0.77175767] - Bias: -1.2119\n",
      "Epoch 241/1000 - Loss: 0.5123 - Weights: [1.49806616 0.77474328] - Bias: -1.2160\n",
      "Epoch 242/1000 - Loss: 0.5118 - Weights: [1.50319123 0.7777266 ] - Bias: -1.2202\n",
      "Epoch 243/1000 - Loss: 0.5112 - Weights: [1.50830845 0.78070763] - Bias: -1.2244\n",
      "Epoch 244/1000 - Loss: 0.5107 - Weights: [1.51341783 0.78368638] - Bias: -1.2285\n",
      "Epoch 245/1000 - Loss: 0.5102 - Weights: [1.51851939 0.78666285] - Bias: -1.2327\n",
      "Epoch 246/1000 - Loss: 0.5097 - Weights: [1.52361315 0.78963704] - Bias: -1.2368\n",
      "Epoch 247/1000 - Loss: 0.5092 - Weights: [1.52869912 0.79260896] - Bias: -1.2409\n",
      "Epoch 248/1000 - Loss: 0.5086 - Weights: [1.53377734 0.7955786 ] - Bias: -1.2451\n",
      "Epoch 249/1000 - Loss: 0.5081 - Weights: [1.53884781 0.79854597] - Bias: -1.2492\n",
      "Epoch 250/1000 - Loss: 0.5076 - Weights: [1.54391055 0.80151108] - Bias: -1.2533\n",
      "Epoch 251/1000 - Loss: 0.5071 - Weights: [1.54896558 0.80447392] - Bias: -1.2574\n",
      "Epoch 252/1000 - Loss: 0.5066 - Weights: [1.55401293 0.8074345 ] - Bias: -1.2616\n",
      "Epoch 253/1000 - Loss: 0.5061 - Weights: [1.5590526  0.81039282] - Bias: -1.2657\n",
      "Epoch 254/1000 - Loss: 0.5056 - Weights: [1.56408462 0.81334888] - Bias: -1.2698\n",
      "Epoch 255/1000 - Loss: 0.5050 - Weights: [1.569109   0.81630269] - Bias: -1.2739\n",
      "Epoch 256/1000 - Loss: 0.5045 - Weights: [1.57412577 0.81925425] - Bias: -1.2780\n",
      "Epoch 257/1000 - Loss: 0.5040 - Weights: [1.57913494 0.82220356] - Bias: -1.2820\n",
      "Epoch 258/1000 - Loss: 0.5035 - Weights: [1.58413652 0.82515062] - Bias: -1.2861\n",
      "Epoch 259/1000 - Loss: 0.5030 - Weights: [1.58913055 0.82809545] - Bias: -1.2902\n",
      "Epoch 260/1000 - Loss: 0.5025 - Weights: [1.59411703 0.83103803] - Bias: -1.2943\n",
      "Epoch 261/1000 - Loss: 0.5020 - Weights: [1.59909598 0.83397837] - Bias: -1.2983\n",
      "Epoch 262/1000 - Loss: 0.5015 - Weights: [1.60406742 0.83691649] - Bias: -1.3024\n",
      "Epoch 263/1000 - Loss: 0.5010 - Weights: [1.60903138 0.83985237] - Bias: -1.3065\n",
      "Epoch 264/1000 - Loss: 0.5005 - Weights: [1.61398786 0.84278602] - Bias: -1.3105\n",
      "Epoch 265/1000 - Loss: 0.5000 - Weights: [1.61893688 0.84571744] - Bias: -1.3145\n",
      "Epoch 266/1000 - Loss: 0.4995 - Weights: [1.62387847 0.84864665] - Bias: -1.3186\n",
      "Epoch 267/1000 - Loss: 0.4990 - Weights: [1.62881263 0.85157363] - Bias: -1.3226\n",
      "Epoch 268/1000 - Loss: 0.4986 - Weights: [1.63373939 0.85449839] - Bias: -1.3267\n",
      "Epoch 269/1000 - Loss: 0.4981 - Weights: [1.63865877 0.85742094] - Bias: -1.3307\n",
      "Epoch 270/1000 - Loss: 0.4976 - Weights: [1.64357078 0.86034128] - Bias: -1.3347\n",
      "Epoch 271/1000 - Loss: 0.4971 - Weights: [1.64847544 0.86325941] - Bias: -1.3387\n",
      "Epoch 272/1000 - Loss: 0.4966 - Weights: [1.65337277 0.86617533] - Bias: -1.3427\n",
      "Epoch 273/1000 - Loss: 0.4961 - Weights: [1.65826279 0.86908905] - Bias: -1.3467\n",
      "Epoch 274/1000 - Loss: 0.4956 - Weights: [1.6631455  0.87200056] - Bias: -1.3507\n",
      "Epoch 275/1000 - Loss: 0.4951 - Weights: [1.66802094 0.87490988] - Bias: -1.3547\n",
      "Epoch 276/1000 - Loss: 0.4947 - Weights: [1.67288911 0.87781701] - Bias: -1.3587\n",
      "Epoch 277/1000 - Loss: 0.4942 - Weights: [1.67775004 0.88072194] - Bias: -1.3627\n",
      "Epoch 278/1000 - Loss: 0.4937 - Weights: [1.68260374 0.88362468] - Bias: -1.3667\n",
      "Epoch 279/1000 - Loss: 0.4932 - Weights: [1.68745023 0.88652523] - Bias: -1.3707\n",
      "Epoch 280/1000 - Loss: 0.4928 - Weights: [1.69228952 0.8894236 ] - Bias: -1.3747\n",
      "Epoch 281/1000 - Loss: 0.4923 - Weights: [1.69712164 0.89231979] - Bias: -1.3786\n",
      "Epoch 282/1000 - Loss: 0.4918 - Weights: [1.7019466 0.8952138] - Bias: -1.3826\n",
      "Epoch 283/1000 - Loss: 0.4913 - Weights: [1.70676441 0.89810564] - Bias: -1.3865\n",
      "Epoch 284/1000 - Loss: 0.4909 - Weights: [1.7115751 0.9009953] - Bias: -1.3905\n",
      "Epoch 285/1000 - Loss: 0.4904 - Weights: [1.71637868 0.90388279] - Bias: -1.3944\n",
      "Epoch 286/1000 - Loss: 0.4899 - Weights: [1.72117517 0.90676811] - Bias: -1.3984\n",
      "Epoch 287/1000 - Loss: 0.4894 - Weights: [1.72596458 0.90965127] - Bias: -1.4023\n",
      "Epoch 288/1000 - Loss: 0.4890 - Weights: [1.73074693 0.91253226] - Bias: -1.4063\n",
      "Epoch 289/1000 - Loss: 0.4885 - Weights: [1.73552225 0.9154111 ] - Bias: -1.4102\n",
      "Epoch 290/1000 - Loss: 0.4880 - Weights: [1.74029053 0.91828778] - Bias: -1.4141\n",
      "Epoch 291/1000 - Loss: 0.4876 - Weights: [1.74505181 0.92116231] - Bias: -1.4180\n",
      "Epoch 292/1000 - Loss: 0.4871 - Weights: [1.7498061  0.92403468] - Bias: -1.4220\n",
      "Epoch 293/1000 - Loss: 0.4867 - Weights: [1.75455341 0.92690491] - Bias: -1.4259\n",
      "Epoch 294/1000 - Loss: 0.4862 - Weights: [1.75929376 0.92977299] - Bias: -1.4298\n",
      "Epoch 295/1000 - Loss: 0.4857 - Weights: [1.76402717 0.93263893] - Bias: -1.4337\n",
      "Epoch 296/1000 - Loss: 0.4853 - Weights: [1.76875365 0.93550273] - Bias: -1.4376\n",
      "Epoch 297/1000 - Loss: 0.4848 - Weights: [1.77347323 0.9383644 ] - Bias: -1.4415\n",
      "Epoch 298/1000 - Loss: 0.4844 - Weights: [1.77818591 0.94122393] - Bias: -1.4453\n",
      "Epoch 299/1000 - Loss: 0.4839 - Weights: [1.78289171 0.94408132] - Bias: -1.4492\n",
      "Epoch 300/1000 - Loss: 0.4835 - Weights: [1.78759066 0.94693659] - Bias: -1.4531\n",
      "Epoch 301/1000 - Loss: 0.4830 - Weights: [1.79228276 0.94978973] - Bias: -1.4570\n",
      "Epoch 302/1000 - Loss: 0.4826 - Weights: [1.79696803 0.95264075] - Bias: -1.4609\n",
      "Epoch 303/1000 - Loss: 0.4821 - Weights: [1.80164649 0.95548965] - Bias: -1.4647\n",
      "Epoch 304/1000 - Loss: 0.4817 - Weights: [1.80631816 0.95833643] - Bias: -1.4686\n",
      "Epoch 305/1000 - Loss: 0.4812 - Weights: [1.81098304 0.9611811 ] - Bias: -1.4724\n",
      "Epoch 306/1000 - Loss: 0.4808 - Weights: [1.81564116 0.96402365] - Bias: -1.4763\n",
      "Epoch 307/1000 - Loss: 0.4803 - Weights: [1.82029254 0.96686409] - Bias: -1.4801\n",
      "Epoch 308/1000 - Loss: 0.4799 - Weights: [1.82493718 0.96970243] - Bias: -1.4840\n",
      "Epoch 309/1000 - Loss: 0.4794 - Weights: [1.82957511 0.97253866] - Bias: -1.4878\n",
      "Epoch 310/1000 - Loss: 0.4790 - Weights: [1.83420633 0.9753728 ] - Bias: -1.4916\n",
      "Epoch 311/1000 - Loss: 0.4785 - Weights: [1.83883087 0.97820483] - Bias: -1.4955\n",
      "Epoch 312/1000 - Loss: 0.4781 - Weights: [1.84344875 0.98103477] - Bias: -1.4993\n",
      "Epoch 313/1000 - Loss: 0.4777 - Weights: [1.84805997 0.98386261] - Bias: -1.5031\n",
      "Epoch 314/1000 - Loss: 0.4772 - Weights: [1.85266455 0.98668836] - Bias: -1.5069\n",
      "Epoch 315/1000 - Loss: 0.4768 - Weights: [1.85726252 0.98951203] - Bias: -1.5107\n",
      "Epoch 316/1000 - Loss: 0.4764 - Weights: [1.86185388 0.99233361] - Bias: -1.5145\n",
      "Epoch 317/1000 - Loss: 0.4759 - Weights: [1.86643864 0.99515311] - Bias: -1.5183\n",
      "Epoch 318/1000 - Loss: 0.4755 - Weights: [1.87101684 0.99797053] - Bias: -1.5221\n",
      "Epoch 319/1000 - Loss: 0.4751 - Weights: [1.87558847 1.00078588] - Bias: -1.5259\n",
      "Epoch 320/1000 - Loss: 0.4746 - Weights: [1.88015356 1.00359915] - Bias: -1.5297\n",
      "Epoch 321/1000 - Loss: 0.4742 - Weights: [1.88471213 1.00641035] - Bias: -1.5335\n",
      "Epoch 322/1000 - Loss: 0.4738 - Weights: [1.88926418 1.00921948] - Bias: -1.5373\n",
      "Epoch 323/1000 - Loss: 0.4733 - Weights: [1.89380973 1.01202654] - Bias: -1.5411\n",
      "Epoch 324/1000 - Loss: 0.4729 - Weights: [1.8983488  1.01483154] - Bias: -1.5448\n",
      "Epoch 325/1000 - Loss: 0.4725 - Weights: [1.9028814  1.01763448] - Bias: -1.5486\n",
      "Epoch 326/1000 - Loss: 0.4721 - Weights: [1.90740755 1.02043537] - Bias: -1.5523\n",
      "Epoch 327/1000 - Loss: 0.4716 - Weights: [1.91192727 1.02323419] - Bias: -1.5561\n",
      "Epoch 328/1000 - Loss: 0.4712 - Weights: [1.91644056 1.02603097] - Bias: -1.5599\n",
      "Epoch 329/1000 - Loss: 0.4708 - Weights: [1.92094745 1.0288257 ] - Bias: -1.5636\n",
      "Epoch 330/1000 - Loss: 0.4704 - Weights: [1.92544795 1.03161838] - Bias: -1.5674\n",
      "Epoch 331/1000 - Loss: 0.4699 - Weights: [1.92994207 1.03440901] - Bias: -1.5711\n",
      "Epoch 332/1000 - Loss: 0.4695 - Weights: [1.93442983 1.03719761] - Bias: -1.5748\n",
      "Epoch 333/1000 - Loss: 0.4691 - Weights: [1.93891124 1.03998416] - Bias: -1.5786\n",
      "Epoch 334/1000 - Loss: 0.4687 - Weights: [1.94338632 1.04276868] - Bias: -1.5823\n",
      "Epoch 335/1000 - Loss: 0.4683 - Weights: [1.94785509 1.04555117] - Bias: -1.5860\n",
      "Epoch 336/1000 - Loss: 0.4679 - Weights: [1.95231755 1.04833163] - Bias: -1.5897\n",
      "Epoch 337/1000 - Loss: 0.4674 - Weights: [1.95677372 1.05111005] - Bias: -1.5934\n",
      "Epoch 338/1000 - Loss: 0.4670 - Weights: [1.96122363 1.05388646] - Bias: -1.5971\n",
      "Epoch 339/1000 - Loss: 0.4666 - Weights: [1.96566727 1.05666084] - Bias: -1.6008\n",
      "Epoch 340/1000 - Loss: 0.4662 - Weights: [1.97010468 1.0594332 ] - Bias: -1.6045\n",
      "Epoch 341/1000 - Loss: 0.4658 - Weights: [1.97453585 1.06220354] - Bias: -1.6082\n",
      "Epoch 342/1000 - Loss: 0.4654 - Weights: [1.97896081 1.06497187] - Bias: -1.6119\n",
      "Epoch 343/1000 - Loss: 0.4650 - Weights: [1.98337957 1.06773818] - Bias: -1.6156\n",
      "Epoch 344/1000 - Loss: 0.4646 - Weights: [1.98779215 1.07050249] - Bias: -1.6193\n",
      "Epoch 345/1000 - Loss: 0.4642 - Weights: [1.99219856 1.07326479] - Bias: -1.6230\n",
      "Epoch 346/1000 - Loss: 0.4638 - Weights: [1.99659881 1.07602509] - Bias: -1.6267\n",
      "Epoch 347/1000 - Loss: 0.4633 - Weights: [2.00099292 1.07878338] - Bias: -1.6303\n",
      "Epoch 348/1000 - Loss: 0.4629 - Weights: [2.0053809  1.08153968] - Bias: -1.6340\n",
      "Epoch 349/1000 - Loss: 0.4625 - Weights: [2.00976277 1.08429398] - Bias: -1.6377\n",
      "Epoch 350/1000 - Loss: 0.4621 - Weights: [2.01413854 1.08704628] - Bias: -1.6413\n",
      "Epoch 351/1000 - Loss: 0.4617 - Weights: [2.01850823 1.0897966 ] - Bias: -1.6450\n",
      "Epoch 352/1000 - Loss: 0.4613 - Weights: [2.02287185 1.09254493] - Bias: -1.6486\n",
      "Epoch 353/1000 - Loss: 0.4609 - Weights: [2.02722941 1.09529127] - Bias: -1.6523\n",
      "Epoch 354/1000 - Loss: 0.4605 - Weights: [2.03158093 1.09803563] - Bias: -1.6559\n",
      "Epoch 355/1000 - Loss: 0.4601 - Weights: [2.03592642 1.10077801] - Bias: -1.6596\n",
      "Epoch 356/1000 - Loss: 0.4597 - Weights: [2.0402659  1.10351841] - Bias: -1.6632\n",
      "Epoch 357/1000 - Loss: 0.4594 - Weights: [2.04459937 1.10625684] - Bias: -1.6668\n",
      "Epoch 358/1000 - Loss: 0.4590 - Weights: [2.04892687 1.10899329] - Bias: -1.6704\n",
      "Epoch 359/1000 - Loss: 0.4586 - Weights: [2.05324839 1.11172778] - Bias: -1.6741\n",
      "Epoch 360/1000 - Loss: 0.4582 - Weights: [2.05756395 1.1144603 ] - Bias: -1.6777\n",
      "Epoch 361/1000 - Loss: 0.4578 - Weights: [2.06187357 1.11719085] - Bias: -1.6813\n",
      "Epoch 362/1000 - Loss: 0.4574 - Weights: [2.06617726 1.11991944] - Bias: -1.6849\n",
      "Epoch 363/1000 - Loss: 0.4570 - Weights: [2.07047503 1.12264608] - Bias: -1.6885\n",
      "Epoch 364/1000 - Loss: 0.4566 - Weights: [2.0747669  1.12537075] - Bias: -1.6921\n",
      "Epoch 365/1000 - Loss: 0.4562 - Weights: [2.07905288 1.12809347] - Bias: -1.6957\n",
      "Epoch 366/1000 - Loss: 0.4558 - Weights: [2.08333298 1.13081424] - Bias: -1.6993\n",
      "Epoch 367/1000 - Loss: 0.4555 - Weights: [2.08760722 1.13353307] - Bias: -1.7029\n",
      "Epoch 368/1000 - Loss: 0.4551 - Weights: [2.09187562 1.13624994] - Bias: -1.7065\n",
      "Epoch 369/1000 - Loss: 0.4547 - Weights: [2.09613818 1.13896487] - Bias: -1.7101\n",
      "Epoch 370/1000 - Loss: 0.4543 - Weights: [2.10039491 1.14167786] - Bias: -1.7136\n",
      "Epoch 371/1000 - Loss: 0.4539 - Weights: [2.10464584 1.14438891] - Bias: -1.7172\n",
      "Epoch 372/1000 - Loss: 0.4535 - Weights: [2.10889098 1.14709803] - Bias: -1.7208\n",
      "Epoch 373/1000 - Loss: 0.4532 - Weights: [2.11313034 1.14980521] - Bias: -1.7243\n",
      "Epoch 374/1000 - Loss: 0.4528 - Weights: [2.11736392 1.15251046] - Bias: -1.7279\n",
      "Epoch 375/1000 - Loss: 0.4524 - Weights: [2.12159176 1.15521379] - Bias: -1.7315\n",
      "Epoch 376/1000 - Loss: 0.4520 - Weights: [2.12581385 1.15791518] - Bias: -1.7350\n",
      "Epoch 377/1000 - Loss: 0.4516 - Weights: [2.13003022 1.16061466] - Bias: -1.7386\n",
      "Epoch 378/1000 - Loss: 0.4513 - Weights: [2.13424087 1.16331221] - Bias: -1.7421\n",
      "Epoch 379/1000 - Loss: 0.4509 - Weights: [2.13844582 1.16600785] - Bias: -1.7456\n",
      "Epoch 380/1000 - Loss: 0.4505 - Weights: [2.14264508 1.16870157] - Bias: -1.7492\n",
      "Epoch 381/1000 - Loss: 0.4501 - Weights: [2.14683867 1.17139338] - Bias: -1.7527\n",
      "Epoch 382/1000 - Loss: 0.4498 - Weights: [2.15102659 1.17408327] - Bias: -1.7562\n",
      "Epoch 383/1000 - Loss: 0.4494 - Weights: [2.15520887 1.17677126] - Bias: -1.7598\n",
      "Epoch 384/1000 - Loss: 0.4490 - Weights: [2.15938551 1.17945735] - Bias: -1.7633\n",
      "Epoch 385/1000 - Loss: 0.4487 - Weights: [2.16355653 1.18214153] - Bias: -1.7668\n",
      "Epoch 386/1000 - Loss: 0.4483 - Weights: [2.16772194 1.18482381] - Bias: -1.7703\n",
      "Epoch 387/1000 - Loss: 0.4479 - Weights: [2.17188175 1.18750419] - Bias: -1.7738\n",
      "Epoch 388/1000 - Loss: 0.4475 - Weights: [2.17603598 1.19018268] - Bias: -1.7773\n",
      "Epoch 389/1000 - Loss: 0.4472 - Weights: [2.18018463 1.19285928] - Bias: -1.7808\n",
      "Epoch 390/1000 - Loss: 0.4468 - Weights: [2.18432773 1.19553398] - Bias: -1.7843\n",
      "Epoch 391/1000 - Loss: 0.4464 - Weights: [2.18846528 1.1982068 ] - Bias: -1.7878\n",
      "Epoch 392/1000 - Loss: 0.4461 - Weights: [2.1925973  1.20087773] - Bias: -1.7913\n",
      "Epoch 393/1000 - Loss: 0.4457 - Weights: [2.1967238  1.20354678] - Bias: -1.7948\n",
      "Epoch 394/1000 - Loss: 0.4454 - Weights: [2.20084479 1.20621395] - Bias: -1.7983\n",
      "Epoch 395/1000 - Loss: 0.4450 - Weights: [2.20496029 1.20887924] - Bias: -1.8018\n",
      "Epoch 396/1000 - Loss: 0.4446 - Weights: [2.2090703  1.21154266] - Bias: -1.8052\n",
      "Epoch 397/1000 - Loss: 0.4443 - Weights: [2.21317484 1.2142042 ] - Bias: -1.8087\n",
      "Epoch 398/1000 - Loss: 0.4439 - Weights: [2.21727393 1.21686388] - Bias: -1.8122\n",
      "Epoch 399/1000 - Loss: 0.4436 - Weights: [2.22136757 1.21952168] - Bias: -1.8156\n",
      "Epoch 400/1000 - Loss: 0.4432 - Weights: [2.22545578 1.22217762] - Bias: -1.8191\n",
      "Epoch 401/1000 - Loss: 0.4428 - Weights: [2.22953857 1.2248317 ] - Bias: -1.8226\n",
      "Epoch 402/1000 - Loss: 0.4425 - Weights: [2.23361595 1.22748392] - Bias: -1.8260\n",
      "Epoch 403/1000 - Loss: 0.4421 - Weights: [2.23768794 1.23013428] - Bias: -1.8295\n",
      "Epoch 404/1000 - Loss: 0.4418 - Weights: [2.24175454 1.23278278] - Bias: -1.8329\n",
      "Epoch 405/1000 - Loss: 0.4414 - Weights: [2.24581578 1.23542944] - Bias: -1.8363\n",
      "Epoch 406/1000 - Loss: 0.4411 - Weights: [2.24987165 1.23807424] - Bias: -1.8398\n",
      "Epoch 407/1000 - Loss: 0.4407 - Weights: [2.25392218 1.24071719] - Bias: -1.8432\n",
      "Epoch 408/1000 - Loss: 0.4404 - Weights: [2.25796738 1.2433583 ] - Bias: -1.8466\n",
      "Epoch 409/1000 - Loss: 0.4400 - Weights: [2.26200725 1.24599756] - Bias: -1.8501\n",
      "Epoch 410/1000 - Loss: 0.4397 - Weights: [2.26604181 1.24863499] - Bias: -1.8535\n",
      "Epoch 411/1000 - Loss: 0.4393 - Weights: [2.27007108 1.25127057] - Bias: -1.8569\n",
      "Epoch 412/1000 - Loss: 0.4390 - Weights: [2.27409506 1.25390432] - Bias: -1.8603\n",
      "Epoch 413/1000 - Loss: 0.4386 - Weights: [2.27811376 1.25653624] - Bias: -1.8637\n",
      "Epoch 414/1000 - Loss: 0.4383 - Weights: [2.28212721 1.25916633] - Bias: -1.8671\n",
      "Epoch 415/1000 - Loss: 0.4379 - Weights: [2.28613541 1.26179458] - Bias: -1.8706\n",
      "Epoch 416/1000 - Loss: 0.4376 - Weights: [2.29013836 1.26442102] - Bias: -1.8740\n",
      "Epoch 417/1000 - Loss: 0.4372 - Weights: [2.2941361  1.26704562] - Bias: -1.8774\n",
      "Epoch 418/1000 - Loss: 0.4369 - Weights: [2.29812861 1.26966841] - Bias: -1.8807\n",
      "Epoch 419/1000 - Loss: 0.4365 - Weights: [2.30211593 1.27228938] - Bias: -1.8841\n",
      "Epoch 420/1000 - Loss: 0.4362 - Weights: [2.30609805 1.27490853] - Bias: -1.8875\n",
      "Epoch 421/1000 - Loss: 0.4359 - Weights: [2.310075   1.27752587] - Bias: -1.8909\n",
      "Epoch 422/1000 - Loss: 0.4355 - Weights: [2.31404678 1.28014139] - Bias: -1.8943\n",
      "Epoch 423/1000 - Loss: 0.4352 - Weights: [2.31801341 1.28275511] - Bias: -1.8977\n",
      "Epoch 424/1000 - Loss: 0.4348 - Weights: [2.32197489 1.28536702] - Bias: -1.9010\n",
      "Epoch 425/1000 - Loss: 0.4345 - Weights: [2.32593124 1.28797713] - Bias: -1.9044\n",
      "Epoch 426/1000 - Loss: 0.4342 - Weights: [2.32988247 1.29058543] - Bias: -1.9078\n",
      "Epoch 427/1000 - Loss: 0.4338 - Weights: [2.33382859 1.29319193] - Bias: -1.9111\n",
      "Epoch 428/1000 - Loss: 0.4335 - Weights: [2.33776961 1.29579664] - Bias: -1.9145\n",
      "Epoch 429/1000 - Loss: 0.4332 - Weights: [2.34170555 1.29839955] - Bias: -1.9178\n",
      "Epoch 430/1000 - Loss: 0.4328 - Weights: [2.34563641 1.30100067] - Bias: -1.9212\n",
      "Epoch 431/1000 - Loss: 0.4325 - Weights: [2.34956221 1.3036    ] - Bias: -1.9245\n",
      "Epoch 432/1000 - Loss: 0.4322 - Weights: [2.35348296 1.30619754] - Bias: -1.9279\n",
      "Epoch 433/1000 - Loss: 0.4318 - Weights: [2.35739867 1.3087933 ] - Bias: -1.9312\n",
      "Epoch 434/1000 - Loss: 0.4315 - Weights: [2.36130935 1.31138727] - Bias: -1.9345\n",
      "Epoch 435/1000 - Loss: 0.4312 - Weights: [2.36521502 1.31397946] - Bias: -1.9379\n",
      "Epoch 436/1000 - Loss: 0.4308 - Weights: [2.36911567 1.31656988] - Bias: -1.9412\n",
      "Epoch 437/1000 - Loss: 0.4305 - Weights: [2.37301133 1.31915852] - Bias: -1.9445\n",
      "Epoch 438/1000 - Loss: 0.4302 - Weights: [2.37690201 1.32174538] - Bias: -1.9479\n",
      "Epoch 439/1000 - Loss: 0.4298 - Weights: [2.38078772 1.32433047] - Bias: -1.9512\n",
      "Epoch 440/1000 - Loss: 0.4295 - Weights: [2.38466847 1.3269138 ] - Bias: -1.9545\n",
      "Epoch 441/1000 - Loss: 0.4292 - Weights: [2.38854426 1.32949536] - Bias: -1.9578\n",
      "Epoch 442/1000 - Loss: 0.4289 - Weights: [2.39241512 1.33207515] - Bias: -1.9611\n",
      "Epoch 443/1000 - Loss: 0.4285 - Weights: [2.39628104 1.33465318] - Bias: -1.9644\n",
      "Epoch 444/1000 - Loss: 0.4282 - Weights: [2.40014206 1.33722945] - Bias: -1.9677\n",
      "Epoch 445/1000 - Loss: 0.4279 - Weights: [2.40399816 1.33980396] - Bias: -1.9710\n",
      "Epoch 446/1000 - Loss: 0.4276 - Weights: [2.40784937 1.34237672] - Bias: -1.9743\n",
      "Epoch 447/1000 - Loss: 0.4272 - Weights: [2.4116957  1.34494773] - Bias: -1.9776\n",
      "Epoch 448/1000 - Loss: 0.4269 - Weights: [2.41553715 1.34751698] - Bias: -1.9809\n",
      "Epoch 449/1000 - Loss: 0.4266 - Weights: [2.41937374 1.35008449] - Bias: -1.9842\n",
      "Epoch 450/1000 - Loss: 0.4263 - Weights: [2.42320548 1.35265025] - Bias: -1.9875\n",
      "Epoch 451/1000 - Loss: 0.4260 - Weights: [2.42703238 1.35521427] - Bias: -1.9907\n",
      "Epoch 452/1000 - Loss: 0.4256 - Weights: [2.43085445 1.35777655] - Bias: -1.9940\n",
      "Epoch 453/1000 - Loss: 0.4253 - Weights: [2.4346717  1.36033709] - Bias: -1.9973\n",
      "Epoch 454/1000 - Loss: 0.4250 - Weights: [2.43848414 1.36289589] - Bias: -2.0005\n",
      "Epoch 455/1000 - Loss: 0.4247 - Weights: [2.44229179 1.36545295] - Bias: -2.0038\n",
      "Epoch 456/1000 - Loss: 0.4244 - Weights: [2.44609465 1.36800829] - Bias: -2.0071\n",
      "Epoch 457/1000 - Loss: 0.4240 - Weights: [2.44989273 1.37056189] - Bias: -2.0103\n",
      "Epoch 458/1000 - Loss: 0.4237 - Weights: [2.45368604 1.37311377] - Bias: -2.0136\n",
      "Epoch 459/1000 - Loss: 0.4234 - Weights: [2.4574746  1.37566392] - Bias: -2.0168\n",
      "Epoch 460/1000 - Loss: 0.4231 - Weights: [2.46125842 1.37821235] - Bias: -2.0201\n",
      "Epoch 461/1000 - Loss: 0.4228 - Weights: [2.4650375  1.38075906] - Bias: -2.0233\n",
      "Epoch 462/1000 - Loss: 0.4225 - Weights: [2.46881186 1.38330405] - Bias: -2.0266\n",
      "Epoch 463/1000 - Loss: 0.4222 - Weights: [2.47258151 1.38584732] - Bias: -2.0298\n",
      "Epoch 464/1000 - Loss: 0.4219 - Weights: [2.47634645 1.38838888] - Bias: -2.0330\n",
      "Epoch 465/1000 - Loss: 0.4215 - Weights: [2.48010671 1.39092873] - Bias: -2.0363\n",
      "Epoch 466/1000 - Loss: 0.4212 - Weights: [2.48386228 1.39346686] - Bias: -2.0395\n",
      "Epoch 467/1000 - Loss: 0.4209 - Weights: [2.48761318 1.39600329] - Bias: -2.0427\n",
      "Epoch 468/1000 - Loss: 0.4206 - Weights: [2.49135942 1.39853802] - Bias: -2.0459\n",
      "Epoch 469/1000 - Loss: 0.4203 - Weights: [2.495101   1.40107104] - Bias: -2.0491\n",
      "Epoch 470/1000 - Loss: 0.4200 - Weights: [2.49883795 1.40360236] - Bias: -2.0524\n",
      "Epoch 471/1000 - Loss: 0.4197 - Weights: [2.50257027 1.40613198] - Bias: -2.0556\n",
      "Epoch 472/1000 - Loss: 0.4194 - Weights: [2.50629796 1.40865991] - Bias: -2.0588\n",
      "Epoch 473/1000 - Loss: 0.4191 - Weights: [2.51002105 1.41118614] - Bias: -2.0620\n",
      "Epoch 474/1000 - Loss: 0.4188 - Weights: [2.51373954 1.41371068] - Bias: -2.0652\n",
      "Epoch 475/1000 - Loss: 0.4185 - Weights: [2.51745344 1.41623353] - Bias: -2.0684\n",
      "Epoch 476/1000 - Loss: 0.4182 - Weights: [2.52116276 1.4187547 ] - Bias: -2.0716\n",
      "Epoch 477/1000 - Loss: 0.4179 - Weights: [2.52486751 1.42127418] - Bias: -2.0748\n",
      "Epoch 478/1000 - Loss: 0.4176 - Weights: [2.5285677  1.42379197] - Bias: -2.0780\n",
      "Epoch 479/1000 - Loss: 0.4173 - Weights: [2.53226334 1.42630809] - Bias: -2.0811\n",
      "Epoch 480/1000 - Loss: 0.4170 - Weights: [2.53595444 1.42882252] - Bias: -2.0843\n",
      "Epoch 481/1000 - Loss: 0.4167 - Weights: [2.53964102 1.43133528] - Bias: -2.0875\n",
      "Epoch 482/1000 - Loss: 0.4164 - Weights: [2.54332307 1.43384637] - Bias: -2.0907\n",
      "Epoch 483/1000 - Loss: 0.4161 - Weights: [2.54700062 1.43635578] - Bias: -2.0938\n",
      "Epoch 484/1000 - Loss: 0.4158 - Weights: [2.55067366 1.43886353] - Bias: -2.0970\n",
      "Epoch 485/1000 - Loss: 0.4155 - Weights: [2.55434222 1.4413696 ] - Bias: -2.1002\n",
      "Epoch 486/1000 - Loss: 0.4152 - Weights: [2.55800629 1.44387401] - Bias: -2.1033\n",
      "Epoch 487/1000 - Loss: 0.4149 - Weights: [2.5616659  1.44637676] - Bias: -2.1065\n",
      "Epoch 488/1000 - Loss: 0.4146 - Weights: [2.56532105 1.44887784] - Bias: -2.1097\n",
      "Epoch 489/1000 - Loss: 0.4143 - Weights: [2.56897174 1.45137727] - Bias: -2.1128\n",
      "Epoch 490/1000 - Loss: 0.4140 - Weights: [2.572618   1.45387504] - Bias: -2.1160\n",
      "Epoch 491/1000 - Loss: 0.4137 - Weights: [2.57625982 1.45637115] - Bias: -2.1191\n",
      "Epoch 492/1000 - Loss: 0.4134 - Weights: [2.57989722 1.45886562] - Bias: -2.1222\n",
      "Epoch 493/1000 - Loss: 0.4131 - Weights: [2.58353021 1.46135843] - Bias: -2.1254\n",
      "Epoch 494/1000 - Loss: 0.4128 - Weights: [2.5871588  1.46384959] - Bias: -2.1285\n",
      "Epoch 495/1000 - Loss: 0.4125 - Weights: [2.590783   1.46633911] - Bias: -2.1317\n",
      "Epoch 496/1000 - Loss: 0.4122 - Weights: [2.59440281 1.46882698] - Bias: -2.1348\n",
      "Epoch 497/1000 - Loss: 0.4119 - Weights: [2.59801825 1.47131321] - Bias: -2.1379\n",
      "Epoch 498/1000 - Loss: 0.4116 - Weights: [2.60162933 1.4737978 ] - Bias: -2.1410\n",
      "Epoch 499/1000 - Loss: 0.4114 - Weights: [2.60523605 1.47628075] - Bias: -2.1442\n",
      "Epoch 500/1000 - Loss: 0.4111 - Weights: [2.60883843 1.47876207] - Bias: -2.1473\n",
      "Epoch 501/1000 - Loss: 0.4108 - Weights: [2.61243647 1.48124176] - Bias: -2.1504\n",
      "Epoch 502/1000 - Loss: 0.4105 - Weights: [2.61603019 1.48371981] - Bias: -2.1535\n",
      "Epoch 503/1000 - Loss: 0.4102 - Weights: [2.61961959 1.48619623] - Bias: -2.1566\n",
      "Epoch 504/1000 - Loss: 0.4099 - Weights: [2.62320468 1.48867103] - Bias: -2.1597\n",
      "Epoch 505/1000 - Loss: 0.4096 - Weights: [2.62678547 1.4911442 ] - Bias: -2.1628\n",
      "Epoch 506/1000 - Loss: 0.4093 - Weights: [2.63036198 1.49361575] - Bias: -2.1659\n",
      "Epoch 507/1000 - Loss: 0.4091 - Weights: [2.6339342  1.49608567] - Bias: -2.1690\n",
      "Epoch 508/1000 - Loss: 0.4088 - Weights: [2.63750216 1.49855398] - Bias: -2.1721\n",
      "Epoch 509/1000 - Loss: 0.4085 - Weights: [2.64106586 1.50102067] - Bias: -2.1752\n",
      "Epoch 510/1000 - Loss: 0.4082 - Weights: [2.6446253  1.50348575] - Bias: -2.1783\n",
      "Epoch 511/1000 - Loss: 0.4079 - Weights: [2.6481805  1.50594921] - Bias: -2.1814\n",
      "Epoch 512/1000 - Loss: 0.4076 - Weights: [2.65173147 1.50841107] - Bias: -2.1845\n",
      "Epoch 513/1000 - Loss: 0.4074 - Weights: [2.65527821 1.51087131] - Bias: -2.1875\n",
      "Epoch 514/1000 - Loss: 0.4071 - Weights: [2.65882074 1.51332995] - Bias: -2.1906\n",
      "Epoch 515/1000 - Loss: 0.4068 - Weights: [2.66235906 1.51578699] - Bias: -2.1937\n",
      "Epoch 516/1000 - Loss: 0.4065 - Weights: [2.66589319 1.51824242] - Bias: -2.1967\n",
      "Epoch 517/1000 - Loss: 0.4062 - Weights: [2.66942313 1.52069625] - Bias: -2.1998\n",
      "Epoch 518/1000 - Loss: 0.4060 - Weights: [2.67294889 1.52314848] - Bias: -2.2029\n",
      "Epoch 519/1000 - Loss: 0.4057 - Weights: [2.67647048 1.52559912] - Bias: -2.2059\n",
      "Epoch 520/1000 - Loss: 0.4054 - Weights: [2.67998791 1.52804816] - Bias: -2.2090\n",
      "Epoch 521/1000 - Loss: 0.4051 - Weights: [2.68350118 1.53049562] - Bias: -2.2120\n",
      "Epoch 522/1000 - Loss: 0.4049 - Weights: [2.68701032 1.53294148] - Bias: -2.2151\n",
      "Epoch 523/1000 - Loss: 0.4046 - Weights: [2.69051532 1.53538575] - Bias: -2.2181\n",
      "Epoch 524/1000 - Loss: 0.4043 - Weights: [2.69401619 1.53782844] - Bias: -2.2212\n",
      "Epoch 525/1000 - Loss: 0.4040 - Weights: [2.69751295 1.54026954] - Bias: -2.2242\n",
      "Epoch 526/1000 - Loss: 0.4037 - Weights: [2.7010056  1.54270906] - Bias: -2.2273\n",
      "Epoch 527/1000 - Loss: 0.4035 - Weights: [2.70449415 1.54514701] - Bias: -2.2303\n",
      "Epoch 528/1000 - Loss: 0.4032 - Weights: [2.70797861 1.54758337] - Bias: -2.2333\n",
      "Epoch 529/1000 - Loss: 0.4029 - Weights: [2.71145899 1.55001816] - Bias: -2.2364\n",
      "Epoch 530/1000 - Loss: 0.4027 - Weights: [2.7149353  1.55245137] - Bias: -2.2394\n",
      "Epoch 531/1000 - Loss: 0.4024 - Weights: [2.71840754 1.55488302] - Bias: -2.2424\n",
      "Epoch 532/1000 - Loss: 0.4021 - Weights: [2.72187573 1.55731309] - Bias: -2.2455\n",
      "Epoch 533/1000 - Loss: 0.4018 - Weights: [2.72533987 1.55974159] - Bias: -2.2485\n",
      "Epoch 534/1000 - Loss: 0.4016 - Weights: [2.72879997 1.56216853] - Bias: -2.2515\n",
      "Epoch 535/1000 - Loss: 0.4013 - Weights: [2.73225605 1.56459391] - Bias: -2.2545\n",
      "Epoch 536/1000 - Loss: 0.4010 - Weights: [2.7357081  1.56701772] - Bias: -2.2575\n",
      "Epoch 537/1000 - Loss: 0.4008 - Weights: [2.73915614 1.56943998] - Bias: -2.2605\n",
      "Epoch 538/1000 - Loss: 0.4005 - Weights: [2.74260018 1.57186067] - Bias: -2.2635\n",
      "Epoch 539/1000 - Loss: 0.4002 - Weights: [2.74604022 1.57427981] - Bias: -2.2665\n",
      "Epoch 540/1000 - Loss: 0.4000 - Weights: [2.74947628 1.5766974 ] - Bias: -2.2695\n",
      "Epoch 541/1000 - Loss: 0.3997 - Weights: [2.75290836 1.57911343] - Bias: -2.2725\n",
      "Epoch 542/1000 - Loss: 0.3994 - Weights: [2.75633647 1.58152792] - Bias: -2.2755\n",
      "Epoch 543/1000 - Loss: 0.3992 - Weights: [2.75976061 1.58394085] - Bias: -2.2785\n",
      "Epoch 544/1000 - Loss: 0.3989 - Weights: [2.76318081 1.58635224] - Bias: -2.2815\n",
      "Epoch 545/1000 - Loss: 0.3986 - Weights: [2.76659706 1.58876209] - Bias: -2.2845\n",
      "Epoch 546/1000 - Loss: 0.3984 - Weights: [2.77000937 1.59117039] - Bias: -2.2875\n",
      "Epoch 547/1000 - Loss: 0.3981 - Weights: [2.77341775 1.59357716] - Bias: -2.2904\n",
      "Epoch 548/1000 - Loss: 0.3978 - Weights: [2.77682222 1.59598238] - Bias: -2.2934\n",
      "Epoch 549/1000 - Loss: 0.3976 - Weights: [2.78022277 1.59838607] - Bias: -2.2964\n",
      "Epoch 550/1000 - Loss: 0.3973 - Weights: [2.78361942 1.60078823] - Bias: -2.2994\n",
      "Epoch 551/1000 - Loss: 0.3971 - Weights: [2.78701218 1.60318885] - Bias: -2.3023\n",
      "Epoch 552/1000 - Loss: 0.3968 - Weights: [2.79040105 1.60558794] - Bias: -2.3053\n",
      "Epoch 553/1000 - Loss: 0.3965 - Weights: [2.79378604 1.60798551] - Bias: -2.3083\n",
      "Epoch 554/1000 - Loss: 0.3963 - Weights: [2.79716716 1.61038154] - Bias: -2.3112\n",
      "Epoch 555/1000 - Loss: 0.3960 - Weights: [2.80054442 1.61277605] - Bias: -2.3142\n",
      "Epoch 556/1000 - Loss: 0.3958 - Weights: [2.80391783 1.61516904] - Bias: -2.3171\n",
      "Epoch 557/1000 - Loss: 0.3955 - Weights: [2.80728738 1.61756051] - Bias: -2.3201\n",
      "Epoch 558/1000 - Loss: 0.3953 - Weights: [2.81065311 1.61995046] - Bias: -2.3230\n",
      "Epoch 559/1000 - Loss: 0.3950 - Weights: [2.814015   1.62233889] - Bias: -2.3260\n",
      "Epoch 560/1000 - Loss: 0.3947 - Weights: [2.81737307 1.62472581] - Bias: -2.3289\n",
      "Epoch 561/1000 - Loss: 0.3945 - Weights: [2.82072732 1.62711122] - Bias: -2.3318\n",
      "Epoch 562/1000 - Loss: 0.3942 - Weights: [2.82407778 1.62949511] - Bias: -2.3348\n",
      "Epoch 563/1000 - Loss: 0.3940 - Weights: [2.82742443 1.63187749] - Bias: -2.3377\n",
      "Epoch 564/1000 - Loss: 0.3937 - Weights: [2.83076729 1.63425837] - Bias: -2.3406\n",
      "Epoch 565/1000 - Loss: 0.3935 - Weights: [2.83410637 1.63663774] - Bias: -2.3436\n",
      "Epoch 566/1000 - Loss: 0.3932 - Weights: [2.83744168 1.63901561] - Bias: -2.3465\n",
      "Epoch 567/1000 - Loss: 0.3930 - Weights: [2.84077322 1.64139197] - Bias: -2.3494\n",
      "Epoch 568/1000 - Loss: 0.3927 - Weights: [2.84410101 1.64376684] - Bias: -2.3523\n",
      "Epoch 569/1000 - Loss: 0.3924 - Weights: [2.84742504 1.6461402 ] - Bias: -2.3553\n",
      "Epoch 570/1000 - Loss: 0.3922 - Weights: [2.85074533 1.64851207] - Bias: -2.3582\n",
      "Epoch 571/1000 - Loss: 0.3919 - Weights: [2.85406189 1.65088245] - Bias: -2.3611\n",
      "Epoch 572/1000 - Loss: 0.3917 - Weights: [2.85737472 1.65325133] - Bias: -2.3640\n",
      "Epoch 573/1000 - Loss: 0.3914 - Weights: [2.86068383 1.65561873] - Bias: -2.3669\n",
      "Epoch 574/1000 - Loss: 0.3912 - Weights: [2.86398923 1.65798463] - Bias: -2.3698\n",
      "Epoch 575/1000 - Loss: 0.3909 - Weights: [2.86729092 1.66034905] - Bias: -2.3727\n",
      "Epoch 576/1000 - Loss: 0.3907 - Weights: [2.87058892 1.66271198] - Bias: -2.3756\n",
      "Epoch 577/1000 - Loss: 0.3904 - Weights: [2.87388324 1.66507343] - Bias: -2.3785\n",
      "Epoch 578/1000 - Loss: 0.3902 - Weights: [2.87717387 1.6674334 ] - Bias: -2.3814\n",
      "Epoch 579/1000 - Loss: 0.3900 - Weights: [2.88046083 1.66979188] - Bias: -2.3843\n",
      "Epoch 580/1000 - Loss: 0.3897 - Weights: [2.88374412 1.67214889] - Bias: -2.3872\n",
      "Epoch 581/1000 - Loss: 0.3895 - Weights: [2.88702375 1.67450443] - Bias: -2.3901\n",
      "Epoch 582/1000 - Loss: 0.3892 - Weights: [2.89029974 1.67685849] - Bias: -2.3930\n",
      "Epoch 583/1000 - Loss: 0.3890 - Weights: [2.89357208 1.67921108] - Bias: -2.3958\n",
      "Epoch 584/1000 - Loss: 0.3887 - Weights: [2.89684079 1.6815622 ] - Bias: -2.3987\n",
      "Epoch 585/1000 - Loss: 0.3885 - Weights: [2.90010587 1.68391185] - Bias: -2.4016\n",
      "Epoch 586/1000 - Loss: 0.3882 - Weights: [2.90336733 1.68626003] - Bias: -2.4045\n",
      "Epoch 587/1000 - Loss: 0.3880 - Weights: [2.90662518 1.68860675] - Bias: -2.4073\n",
      "Epoch 588/1000 - Loss: 0.3877 - Weights: [2.90987942 1.690952  ] - Bias: -2.4102\n",
      "Epoch 589/1000 - Loss: 0.3875 - Weights: [2.91313007 1.6932958 ] - Bias: -2.4131\n",
      "Epoch 590/1000 - Loss: 0.3873 - Weights: [2.91637712 1.69563813] - Bias: -2.4159\n",
      "Epoch 591/1000 - Loss: 0.3870 - Weights: [2.91962059 1.69797901] - Bias: -2.4188\n",
      "Epoch 592/1000 - Loss: 0.3868 - Weights: [2.92286049 1.70031843] - Bias: -2.4216\n",
      "Epoch 593/1000 - Loss: 0.3865 - Weights: [2.92609682 1.7026564 ] - Bias: -2.4245\n",
      "Epoch 594/1000 - Loss: 0.3863 - Weights: [2.92932959 1.70499291] - Bias: -2.4273\n",
      "Epoch 595/1000 - Loss: 0.3861 - Weights: [2.9325588  1.70732798] - Bias: -2.4302\n",
      "Epoch 596/1000 - Loss: 0.3858 - Weights: [2.93578447 1.70966159] - Bias: -2.4330\n",
      "Epoch 597/1000 - Loss: 0.3856 - Weights: [2.9390066  1.71199376] - Bias: -2.4359\n",
      "Epoch 598/1000 - Loss: 0.3853 - Weights: [2.9422252  1.71432449] - Bias: -2.4387\n",
      "Epoch 599/1000 - Loss: 0.3851 - Weights: [2.94544027 1.71665377] - Bias: -2.4416\n",
      "Epoch 600/1000 - Loss: 0.3849 - Weights: [2.94865183 1.71898161] - Bias: -2.4444\n",
      "Epoch 601/1000 - Loss: 0.3846 - Weights: [2.95185988 1.72130801] - Bias: -2.4472\n",
      "Epoch 602/1000 - Loss: 0.3844 - Weights: [2.95506442 1.72363297] - Bias: -2.4501\n",
      "Epoch 603/1000 - Loss: 0.3841 - Weights: [2.95826547 1.72595649] - Bias: -2.4529\n",
      "Epoch 604/1000 - Loss: 0.3839 - Weights: [2.96146303 1.72827858] - Bias: -2.4557\n",
      "Epoch 605/1000 - Loss: 0.3837 - Weights: [2.96465711 1.73059924] - Bias: -2.4585\n",
      "Epoch 606/1000 - Loss: 0.3834 - Weights: [2.96784772 1.73291847] - Bias: -2.4614\n",
      "Epoch 607/1000 - Loss: 0.3832 - Weights: [2.97103485 1.73523627] - Bias: -2.4642\n",
      "Epoch 608/1000 - Loss: 0.3830 - Weights: [2.97421853 1.73755264] - Bias: -2.4670\n",
      "Epoch 609/1000 - Loss: 0.3827 - Weights: [2.97739876 1.73986759] - Bias: -2.4698\n",
      "Epoch 610/1000 - Loss: 0.3825 - Weights: [2.98057554 1.74218111] - Bias: -2.4726\n",
      "Epoch 611/1000 - Loss: 0.3823 - Weights: [2.98374888 1.74449321] - Bias: -2.4754\n",
      "Epoch 612/1000 - Loss: 0.3820 - Weights: [2.98691879 1.74680389] - Bias: -2.4782\n",
      "Epoch 613/1000 - Loss: 0.3818 - Weights: [2.99008527 1.74911315] - Bias: -2.4810\n",
      "Epoch 614/1000 - Loss: 0.3816 - Weights: [2.99324834 1.75142099] - Bias: -2.4838\n",
      "Epoch 615/1000 - Loss: 0.3813 - Weights: [2.99640799 1.75372742] - Bias: -2.4866\n",
      "Epoch 616/1000 - Loss: 0.3811 - Weights: [2.99956424 1.75603243] - Bias: -2.4894\n",
      "Epoch 617/1000 - Loss: 0.3809 - Weights: [3.0027171  1.75833604] - Bias: -2.4922\n",
      "Epoch 618/1000 - Loss: 0.3806 - Weights: [3.00586656 1.76063823] - Bias: -2.4950\n",
      "Epoch 619/1000 - Loss: 0.3804 - Weights: [3.00901264 1.76293901] - Bias: -2.4978\n",
      "Epoch 620/1000 - Loss: 0.3802 - Weights: [3.01215534 1.76523839] - Bias: -2.5006\n",
      "Epoch 621/1000 - Loss: 0.3800 - Weights: [3.01529468 1.76753637] - Bias: -2.5034\n",
      "Epoch 622/1000 - Loss: 0.3797 - Weights: [3.01843065 1.76983294] - Bias: -2.5061\n",
      "Epoch 623/1000 - Loss: 0.3795 - Weights: [3.02156326 1.7721281 ] - Bias: -2.5089\n",
      "Epoch 624/1000 - Loss: 0.3793 - Weights: [3.02469253 1.77442187] - Bias: -2.5117\n",
      "Epoch 625/1000 - Loss: 0.3790 - Weights: [3.02781845 1.77671424] - Bias: -2.5145\n",
      "Epoch 626/1000 - Loss: 0.3788 - Weights: [3.03094104 1.77900522] - Bias: -2.5172\n",
      "Epoch 627/1000 - Loss: 0.3786 - Weights: [3.0340603 1.7812948] - Bias: -2.5200\n",
      "Epoch 628/1000 - Loss: 0.3784 - Weights: [3.03717624 1.78358299] - Bias: -2.5228\n",
      "Epoch 629/1000 - Loss: 0.3781 - Weights: [3.04028886 1.78586978] - Bias: -2.5255\n",
      "Epoch 630/1000 - Loss: 0.3779 - Weights: [3.04339817 1.78815519] - Bias: -2.5283\n",
      "Epoch 631/1000 - Loss: 0.3777 - Weights: [3.04650418 1.79043921] - Bias: -2.5311\n",
      "Epoch 632/1000 - Loss: 0.3775 - Weights: [3.04960689 1.79272184] - Bias: -2.5338\n",
      "Epoch 633/1000 - Loss: 0.3772 - Weights: [3.05270631 1.79500309] - Bias: -2.5366\n",
      "Epoch 634/1000 - Loss: 0.3770 - Weights: [3.05580245 1.79728295] - Bias: -2.5393\n",
      "Epoch 635/1000 - Loss: 0.3768 - Weights: [3.05889532 1.79956144] - Bias: -2.5421\n",
      "Epoch 636/1000 - Loss: 0.3766 - Weights: [3.06198492 1.80183854] - Bias: -2.5448\n",
      "Epoch 637/1000 - Loss: 0.3763 - Weights: [3.06507125 1.80411427] - Bias: -2.5476\n",
      "Epoch 638/1000 - Loss: 0.3761 - Weights: [3.06815433 1.80638862] - Bias: -2.5503\n",
      "Epoch 639/1000 - Loss: 0.3759 - Weights: [3.07123416 1.8086616 ] - Bias: -2.5530\n",
      "Epoch 640/1000 - Loss: 0.3757 - Weights: [3.07431074 1.8109332 ] - Bias: -2.5558\n",
      "Epoch 641/1000 - Loss: 0.3755 - Weights: [3.07738409 1.81320343] - Bias: -2.5585\n",
      "Epoch 642/1000 - Loss: 0.3752 - Weights: [3.08045421 1.81547229] - Bias: -2.5612\n",
      "Epoch 643/1000 - Loss: 0.3750 - Weights: [3.0835211  1.81773979] - Bias: -2.5640\n",
      "Epoch 644/1000 - Loss: 0.3748 - Weights: [3.08658478 1.82000592] - Bias: -2.5667\n",
      "Epoch 645/1000 - Loss: 0.3746 - Weights: [3.08964524 1.82227068] - Bias: -2.5694\n",
      "Epoch 646/1000 - Loss: 0.3744 - Weights: [3.0927025  1.82453408] - Bias: -2.5722\n",
      "Epoch 647/1000 - Loss: 0.3741 - Weights: [3.09575656 1.82679612] - Bias: -2.5749\n",
      "Epoch 648/1000 - Loss: 0.3739 - Weights: [3.09880743 1.8290568 ] - Bias: -2.5776\n",
      "Epoch 649/1000 - Loss: 0.3737 - Weights: [3.10185512 1.83131612] - Bias: -2.5803\n",
      "Epoch 650/1000 - Loss: 0.3735 - Weights: [3.10489963 1.83357409] - Bias: -2.5830\n",
      "Epoch 651/1000 - Loss: 0.3733 - Weights: [3.10794096 1.8358307 ] - Bias: -2.5857\n",
      "Epoch 652/1000 - Loss: 0.3731 - Weights: [3.11097913 1.83808595] - Bias: -2.5884\n",
      "Epoch 653/1000 - Loss: 0.3728 - Weights: [3.11401413 1.84033986] - Bias: -2.5911\n",
      "Epoch 654/1000 - Loss: 0.3726 - Weights: [3.11704598 1.84259242] - Bias: -2.5939\n",
      "Epoch 655/1000 - Loss: 0.3724 - Weights: [3.12007469 1.84484362] - Bias: -2.5966\n",
      "Epoch 656/1000 - Loss: 0.3722 - Weights: [3.12310025 1.84709348] - Bias: -2.5993\n",
      "Epoch 657/1000 - Loss: 0.3720 - Weights: [3.12612268 1.849342  ] - Bias: -2.6019\n",
      "Epoch 658/1000 - Loss: 0.3718 - Weights: [3.12914198 1.85158917] - Bias: -2.6046\n",
      "Epoch 659/1000 - Loss: 0.3715 - Weights: [3.13215815 1.853835  ] - Bias: -2.6073\n",
      "Epoch 660/1000 - Loss: 0.3713 - Weights: [3.13517121 1.85607949] - Bias: -2.6100\n",
      "Epoch 661/1000 - Loss: 0.3711 - Weights: [3.13818116 1.85832264] - Bias: -2.6127\n",
      "Epoch 662/1000 - Loss: 0.3709 - Weights: [3.14118801 1.86056446] - Bias: -2.6154\n",
      "Epoch 663/1000 - Loss: 0.3707 - Weights: [3.14419175 1.86280494] - Bias: -2.6181\n",
      "Epoch 664/1000 - Loss: 0.3705 - Weights: [3.14719241 1.86504408] - Bias: -2.6208\n",
      "Epoch 665/1000 - Loss: 0.3703 - Weights: [3.15018997 1.8672819 ] - Bias: -2.6234\n",
      "Epoch 666/1000 - Loss: 0.3701 - Weights: [3.15318446 1.86951838] - Bias: -2.6261\n",
      "Epoch 667/1000 - Loss: 0.3698 - Weights: [3.15617587 1.87175353] - Bias: -2.6288\n",
      "Epoch 668/1000 - Loss: 0.3696 - Weights: [3.15916422 1.87398736] - Bias: -2.6315\n",
      "Epoch 669/1000 - Loss: 0.3694 - Weights: [3.1621495  1.87621986] - Bias: -2.6341\n",
      "Epoch 670/1000 - Loss: 0.3692 - Weights: [3.16513173 1.87845103] - Bias: -2.6368\n",
      "Epoch 671/1000 - Loss: 0.3690 - Weights: [3.16811091 1.88068088] - Bias: -2.6395\n",
      "Epoch 672/1000 - Loss: 0.3688 - Weights: [3.17108704 1.88290941] - Bias: -2.6421\n",
      "Epoch 673/1000 - Loss: 0.3686 - Weights: [3.17406014 1.88513662] - Bias: -2.6448\n",
      "Epoch 674/1000 - Loss: 0.3684 - Weights: [3.1770302  1.88736252] - Bias: -2.6474\n",
      "Epoch 675/1000 - Loss: 0.3682 - Weights: [3.17999724 1.88958709] - Bias: -2.6501\n",
      "Epoch 676/1000 - Loss: 0.3680 - Weights: [3.18296126 1.89181036] - Bias: -2.6528\n",
      "Epoch 677/1000 - Loss: 0.3678 - Weights: [3.18592226 1.8940323 ] - Bias: -2.6554\n",
      "Epoch 678/1000 - Loss: 0.3675 - Weights: [3.18888025 1.89625294] - Bias: -2.6581\n",
      "Epoch 679/1000 - Loss: 0.3673 - Weights: [3.19183525 1.89847227] - Bias: -2.6607\n",
      "Epoch 680/1000 - Loss: 0.3671 - Weights: [3.19478724 1.90069028] - Bias: -2.6633\n",
      "Epoch 681/1000 - Loss: 0.3669 - Weights: [3.19773625 1.90290699] - Bias: -2.6660\n",
      "Epoch 682/1000 - Loss: 0.3667 - Weights: [3.20068227 1.9051224 ] - Bias: -2.6686\n",
      "Epoch 683/1000 - Loss: 0.3665 - Weights: [3.20362531 1.9073365 ] - Bias: -2.6713\n",
      "Epoch 684/1000 - Loss: 0.3663 - Weights: [3.20656538 1.90954929] - Bias: -2.6739\n",
      "Epoch 685/1000 - Loss: 0.3661 - Weights: [3.20950248 1.91176079] - Bias: -2.6765\n",
      "Epoch 686/1000 - Loss: 0.3659 - Weights: [3.21243661 1.91397098] - Bias: -2.6792\n",
      "Epoch 687/1000 - Loss: 0.3657 - Weights: [3.21536779 1.91617988] - Bias: -2.6818\n",
      "Epoch 688/1000 - Loss: 0.3655 - Weights: [3.21829603 1.91838748] - Bias: -2.6844\n",
      "Epoch 689/1000 - Loss: 0.3653 - Weights: [3.22122131 1.92059379] - Bias: -2.6870\n",
      "Epoch 690/1000 - Loss: 0.3651 - Weights: [3.22414366 1.9227988 ] - Bias: -2.6897\n",
      "Epoch 691/1000 - Loss: 0.3649 - Weights: [3.22706308 1.92500252] - Bias: -2.6923\n",
      "Epoch 692/1000 - Loss: 0.3647 - Weights: [3.22997956 1.92720496] - Bias: -2.6949\n",
      "Epoch 693/1000 - Loss: 0.3645 - Weights: [3.23289313 1.9294061 ] - Bias: -2.6975\n",
      "Epoch 694/1000 - Loss: 0.3643 - Weights: [3.23580378 1.93160595] - Bias: -2.7001\n",
      "Epoch 695/1000 - Loss: 0.3641 - Weights: [3.23871152 1.93380452] - Bias: -2.7027\n",
      "Epoch 696/1000 - Loss: 0.3639 - Weights: [3.24161635 1.9360018 ] - Bias: -2.7054\n",
      "Epoch 697/1000 - Loss: 0.3637 - Weights: [3.24451828 1.9381978 ] - Bias: -2.7080\n",
      "Epoch 698/1000 - Loss: 0.3635 - Weights: [3.24741733 1.94039252] - Bias: -2.7106\n",
      "Epoch 699/1000 - Loss: 0.3633 - Weights: [3.25031348 1.94258596] - Bias: -2.7132\n",
      "Epoch 700/1000 - Loss: 0.3631 - Weights: [3.25320675 1.94477813] - Bias: -2.7158\n",
      "Epoch 701/1000 - Loss: 0.3629 - Weights: [3.25609714 1.94696901] - Bias: -2.7184\n",
      "Epoch 702/1000 - Loss: 0.3627 - Weights: [3.25898466 1.94915862] - Bias: -2.7210\n",
      "Epoch 703/1000 - Loss: 0.3625 - Weights: [3.26186932 1.95134695] - Bias: -2.7236\n",
      "Epoch 704/1000 - Loss: 0.3623 - Weights: [3.26475111 1.95353402] - Bias: -2.7262\n",
      "Epoch 705/1000 - Loss: 0.3621 - Weights: [3.26763005 1.95571981] - Bias: -2.7287\n",
      "Epoch 706/1000 - Loss: 0.3619 - Weights: [3.27050614 1.95790433] - Bias: -2.7313\n",
      "Epoch 707/1000 - Loss: 0.3617 - Weights: [3.27337939 1.96008758] - Bias: -2.7339\n",
      "Epoch 708/1000 - Loss: 0.3615 - Weights: [3.2762498  1.96226957] - Bias: -2.7365\n",
      "Epoch 709/1000 - Loss: 0.3613 - Weights: [3.27911737 1.96445029] - Bias: -2.7391\n",
      "Epoch 710/1000 - Loss: 0.3611 - Weights: [3.28198212 1.96662975] - Bias: -2.7417\n",
      "Epoch 711/1000 - Loss: 0.3609 - Weights: [3.28484404 1.96880795] - Bias: -2.7442\n",
      "Epoch 712/1000 - Loss: 0.3607 - Weights: [3.28770315 1.97098488] - Bias: -2.7468\n",
      "Epoch 713/1000 - Loss: 0.3605 - Weights: [3.29055944 1.97316056] - Bias: -2.7494\n",
      "Epoch 714/1000 - Loss: 0.3603 - Weights: [3.29341293 1.97533498] - Bias: -2.7520\n",
      "Epoch 715/1000 - Loss: 0.3601 - Weights: [3.29626362 1.97750814] - Bias: -2.7545\n",
      "Epoch 716/1000 - Loss: 0.3599 - Weights: [3.29911152 1.97968005] - Bias: -2.7571\n",
      "Epoch 717/1000 - Loss: 0.3597 - Weights: [3.30195662 1.9818507 ] - Bias: -2.7597\n",
      "Epoch 718/1000 - Loss: 0.3595 - Weights: [3.30479894 1.9840201 ] - Bias: -2.7622\n",
      "Epoch 719/1000 - Loss: 0.3593 - Weights: [3.30763848 1.98618825] - Bias: -2.7648\n",
      "Epoch 720/1000 - Loss: 0.3592 - Weights: [3.31047524 1.98835516] - Bias: -2.7673\n",
      "Epoch 721/1000 - Loss: 0.3590 - Weights: [3.31330924 1.99052081] - Bias: -2.7699\n",
      "Epoch 722/1000 - Loss: 0.3588 - Weights: [3.31614047 1.99268522] - Bias: -2.7724\n",
      "Epoch 723/1000 - Loss: 0.3586 - Weights: [3.31896894 1.99484838] - Bias: -2.7750\n",
      "Epoch 724/1000 - Loss: 0.3584 - Weights: [3.32179466 1.9970103 ] - Bias: -2.7776\n",
      "Epoch 725/1000 - Loss: 0.3582 - Weights: [3.32461764 1.99917098] - Bias: -2.7801\n",
      "Epoch 726/1000 - Loss: 0.3580 - Weights: [3.32743787 2.00133042] - Bias: -2.7826\n",
      "Epoch 727/1000 - Loss: 0.3578 - Weights: [3.33025536 2.00348862] - Bias: -2.7852\n",
      "Epoch 728/1000 - Loss: 0.3576 - Weights: [3.33307012 2.00564558] - Bias: -2.7877\n",
      "Epoch 729/1000 - Loss: 0.3574 - Weights: [3.33588215 2.00780131] - Bias: -2.7903\n",
      "Epoch 730/1000 - Loss: 0.3572 - Weights: [3.33869146 2.0099558 ] - Bias: -2.7928\n",
      "Epoch 731/1000 - Loss: 0.3570 - Weights: [3.34149805 2.01210905] - Bias: -2.7953\n",
      "Epoch 732/1000 - Loss: 0.3569 - Weights: [3.34430193 2.01426108] - Bias: -2.7979\n",
      "Epoch 733/1000 - Loss: 0.3567 - Weights: [3.34710311 2.01641187] - Bias: -2.8004\n",
      "Epoch 734/1000 - Loss: 0.3565 - Weights: [3.34990158 2.01856144] - Bias: -2.8029\n",
      "Epoch 735/1000 - Loss: 0.3563 - Weights: [3.35269736 2.02070978] - Bias: -2.8055\n",
      "Epoch 736/1000 - Loss: 0.3561 - Weights: [3.35549044 2.02285689] - Bias: -2.8080\n",
      "Epoch 737/1000 - Loss: 0.3559 - Weights: [3.35828084 2.02500278] - Bias: -2.8105\n",
      "Epoch 738/1000 - Loss: 0.3557 - Weights: [3.36106856 2.02714744] - Bias: -2.8130\n",
      "Epoch 739/1000 - Loss: 0.3555 - Weights: [3.3638536  2.02929088] - Bias: -2.8156\n",
      "Epoch 740/1000 - Loss: 0.3554 - Weights: [3.36663597 2.0314331 ] - Bias: -2.8181\n",
      "Epoch 741/1000 - Loss: 0.3552 - Weights: [3.36941567 2.0335741 ] - Bias: -2.8206\n",
      "Epoch 742/1000 - Loss: 0.3550 - Weights: [3.37219272 2.03571388] - Bias: -2.8231\n",
      "Epoch 743/1000 - Loss: 0.3548 - Weights: [3.3749671  2.03785245] - Bias: -2.8256\n",
      "Epoch 744/1000 - Loss: 0.3546 - Weights: [3.37773884 2.0399898 ] - Bias: -2.8281\n",
      "Epoch 745/1000 - Loss: 0.3544 - Weights: [3.38050793 2.04212594] - Bias: -2.8306\n",
      "Epoch 746/1000 - Loss: 0.3542 - Weights: [3.38327437 2.04426086] - Bias: -2.8331\n",
      "Epoch 747/1000 - Loss: 0.3541 - Weights: [3.38603818 2.04639458] - Bias: -2.8356\n",
      "Epoch 748/1000 - Loss: 0.3539 - Weights: [3.38879936 2.04852708] - Bias: -2.8381\n",
      "Epoch 749/1000 - Loss: 0.3537 - Weights: [3.39155792 2.05065838] - Bias: -2.8406\n",
      "Epoch 750/1000 - Loss: 0.3535 - Weights: [3.39431385 2.05278847] - Bias: -2.8431\n",
      "Epoch 751/1000 - Loss: 0.3533 - Weights: [3.39706716 2.05491735] - Bias: -2.8456\n",
      "Epoch 752/1000 - Loss: 0.3531 - Weights: [3.39981786 2.05704503] - Bias: -2.8481\n",
      "Epoch 753/1000 - Loss: 0.3530 - Weights: [3.40256596 2.05917151] - Bias: -2.8506\n",
      "Epoch 754/1000 - Loss: 0.3528 - Weights: [3.40531145 2.06129678] - Bias: -2.8531\n",
      "Epoch 755/1000 - Loss: 0.3526 - Weights: [3.40805435 2.06342086] - Bias: -2.8556\n",
      "Epoch 756/1000 - Loss: 0.3524 - Weights: [3.41079465 2.06554374] - Bias: -2.8581\n",
      "Epoch 757/1000 - Loss: 0.3522 - Weights: [3.41353237 2.06766542] - Bias: -2.8606\n",
      "Epoch 758/1000 - Loss: 0.3520 - Weights: [3.4162675 2.0697859] - Bias: -2.8630\n",
      "Epoch 759/1000 - Loss: 0.3519 - Weights: [3.41900006 2.07190519] - Bias: -2.8655\n",
      "Epoch 760/1000 - Loss: 0.3517 - Weights: [3.42173004 2.07402328] - Bias: -2.8680\n",
      "Epoch 761/1000 - Loss: 0.3515 - Weights: [3.42445745 2.07614019] - Bias: -2.8705\n",
      "Epoch 762/1000 - Loss: 0.3513 - Weights: [3.4271823 2.0782559] - Bias: -2.8729\n",
      "Epoch 763/1000 - Loss: 0.3511 - Weights: [3.42990459 2.08037042] - Bias: -2.8754\n",
      "Epoch 764/1000 - Loss: 0.3510 - Weights: [3.43262433 2.08248376] - Bias: -2.8779\n",
      "Epoch 765/1000 - Loss: 0.3508 - Weights: [3.43534151 2.08459591] - Bias: -2.8804\n",
      "Epoch 766/1000 - Loss: 0.3506 - Weights: [3.43805615 2.08670687] - Bias: -2.8828\n",
      "Epoch 767/1000 - Loss: 0.3504 - Weights: [3.44076826 2.08881665] - Bias: -2.8853\n",
      "Epoch 768/1000 - Loss: 0.3502 - Weights: [3.44347782 2.09092525] - Bias: -2.8878\n",
      "Epoch 769/1000 - Loss: 0.3501 - Weights: [3.44618486 2.09303267] - Bias: -2.8902\n",
      "Epoch 770/1000 - Loss: 0.3499 - Weights: [3.44888937 2.0951389 ] - Bias: -2.8927\n",
      "Epoch 771/1000 - Loss: 0.3497 - Weights: [3.45159135 2.09724396] - Bias: -2.8951\n",
      "Epoch 772/1000 - Loss: 0.3495 - Weights: [3.45429082 2.09934784] - Bias: -2.8976\n",
      "Epoch 773/1000 - Loss: 0.3494 - Weights: [3.45698778 2.10145055] - Bias: -2.9000\n",
      "Epoch 774/1000 - Loss: 0.3492 - Weights: [3.45968223 2.10355208] - Bias: -2.9025\n",
      "Epoch 775/1000 - Loss: 0.3490 - Weights: [3.46237418 2.10565243] - Bias: -2.9049\n",
      "Epoch 776/1000 - Loss: 0.3488 - Weights: [3.46506363 2.10775162] - Bias: -2.9074\n",
      "Epoch 777/1000 - Loss: 0.3486 - Weights: [3.46775059 2.10984963] - Bias: -2.9098\n",
      "Epoch 778/1000 - Loss: 0.3485 - Weights: [3.47043506 2.11194648] - Bias: -2.9123\n",
      "Epoch 779/1000 - Loss: 0.3483 - Weights: [3.47311704 2.11404215] - Bias: -2.9147\n",
      "Epoch 780/1000 - Loss: 0.3481 - Weights: [3.47579654 2.11613666] - Bias: -2.9171\n",
      "Epoch 781/1000 - Loss: 0.3479 - Weights: [3.47847357 2.11823001] - Bias: -2.9196\n",
      "Epoch 782/1000 - Loss: 0.3478 - Weights: [3.48114812 2.12032219] - Bias: -2.9220\n",
      "Epoch 783/1000 - Loss: 0.3476 - Weights: [3.48382021 2.1224132 ] - Bias: -2.9245\n",
      "Epoch 784/1000 - Loss: 0.3474 - Weights: [3.48648984 2.12450306] - Bias: -2.9269\n",
      "Epoch 785/1000 - Loss: 0.3472 - Weights: [3.48915701 2.12659175] - Bias: -2.9293\n",
      "Epoch 786/1000 - Loss: 0.3471 - Weights: [3.49182172 2.12867929] - Bias: -2.9317\n",
      "Epoch 787/1000 - Loss: 0.3469 - Weights: [3.49448399 2.13076567] - Bias: -2.9342\n",
      "Epoch 788/1000 - Loss: 0.3467 - Weights: [3.49714381 2.13285089] - Bias: -2.9366\n",
      "Epoch 789/1000 - Loss: 0.3466 - Weights: [3.4998012  2.13493496] - Bias: -2.9390\n",
      "Epoch 790/1000 - Loss: 0.3464 - Weights: [3.50245615 2.13701787] - Bias: -2.9414\n",
      "Epoch 791/1000 - Loss: 0.3462 - Weights: [3.50510867 2.13909963] - Bias: -2.9439\n",
      "Epoch 792/1000 - Loss: 0.3460 - Weights: [3.50775876 2.14118024] - Bias: -2.9463\n",
      "Epoch 793/1000 - Loss: 0.3459 - Weights: [3.51040643 2.1432597 ] - Bias: -2.9487\n",
      "Epoch 794/1000 - Loss: 0.3457 - Weights: [3.51305168 2.14533801] - Bias: -2.9511\n",
      "Epoch 795/1000 - Loss: 0.3455 - Weights: [3.51569452 2.14741517] - Bias: -2.9535\n",
      "Epoch 796/1000 - Loss: 0.3454 - Weights: [3.51833495 2.14949119] - Bias: -2.9559\n",
      "Epoch 797/1000 - Loss: 0.3452 - Weights: [3.52097298 2.15156606] - Bias: -2.9583\n",
      "Epoch 798/1000 - Loss: 0.3450 - Weights: [3.5236086  2.15363979] - Bias: -2.9607\n",
      "Epoch 799/1000 - Loss: 0.3448 - Weights: [3.52624183 2.15571238] - Bias: -2.9631\n",
      "Epoch 800/1000 - Loss: 0.3447 - Weights: [3.52887267 2.15778382] - Bias: -2.9655\n",
      "Epoch 801/1000 - Loss: 0.3445 - Weights: [3.53150112 2.15985413] - Bias: -2.9679\n",
      "Epoch 802/1000 - Loss: 0.3443 - Weights: [3.53412719 2.16192329] - Bias: -2.9703\n",
      "Epoch 803/1000 - Loss: 0.3442 - Weights: [3.53675088 2.16399132] - Bias: -2.9727\n",
      "Epoch 804/1000 - Loss: 0.3440 - Weights: [3.5393722  2.16605822] - Bias: -2.9751\n",
      "Epoch 805/1000 - Loss: 0.3438 - Weights: [3.54199114 2.16812397] - Bias: -2.9775\n",
      "Epoch 806/1000 - Loss: 0.3437 - Weights: [3.54460773 2.1701886 ] - Bias: -2.9799\n",
      "Epoch 807/1000 - Loss: 0.3435 - Weights: [3.54722195 2.17225209] - Bias: -2.9823\n",
      "Epoch 808/1000 - Loss: 0.3433 - Weights: [3.54983381 2.17431445] - Bias: -2.9847\n",
      "Epoch 809/1000 - Loss: 0.3431 - Weights: [3.55244332 2.17637568] - Bias: -2.9871\n",
      "Epoch 810/1000 - Loss: 0.3430 - Weights: [3.55505048 2.17843579] - Bias: -2.9895\n",
      "Epoch 811/1000 - Loss: 0.3428 - Weights: [3.5576553  2.18049476] - Bias: -2.9918\n",
      "Epoch 812/1000 - Loss: 0.3426 - Weights: [3.56025777 2.18255261] - Bias: -2.9942\n",
      "Epoch 813/1000 - Loss: 0.3425 - Weights: [3.56285791 2.18460933] - Bias: -2.9966\n",
      "Epoch 814/1000 - Loss: 0.3423 - Weights: [3.56545572 2.18666493] - Bias: -2.9990\n",
      "Epoch 815/1000 - Loss: 0.3421 - Weights: [3.5680512  2.18871941] - Bias: -3.0014\n",
      "Epoch 816/1000 - Loss: 0.3420 - Weights: [3.57064436 2.19077277] - Bias: -3.0037\n",
      "Epoch 817/1000 - Loss: 0.3418 - Weights: [3.5732352  2.19282501] - Bias: -3.0061\n",
      "Epoch 818/1000 - Loss: 0.3417 - Weights: [3.57582372 2.19487613] - Bias: -3.0085\n",
      "Epoch 819/1000 - Loss: 0.3415 - Weights: [3.57840993 2.19692613] - Bias: -3.0108\n",
      "Epoch 820/1000 - Loss: 0.3413 - Weights: [3.58099384 2.19897501] - Bias: -3.0132\n",
      "Epoch 821/1000 - Loss: 0.3412 - Weights: [3.58357544 2.20102278] - Bias: -3.0156\n",
      "Epoch 822/1000 - Loss: 0.3410 - Weights: [3.58615474 2.20306943] - Bias: -3.0179\n",
      "Epoch 823/1000 - Loss: 0.3408 - Weights: [3.58873175 2.20511498] - Bias: -3.0203\n",
      "Epoch 824/1000 - Loss: 0.3407 - Weights: [3.59130647 2.20715941] - Bias: -3.0227\n",
      "Epoch 825/1000 - Loss: 0.3405 - Weights: [3.5938789  2.20920273] - Bias: -3.0250\n",
      "Epoch 826/1000 - Loss: 0.3403 - Weights: [3.59644905 2.21124494] - Bias: -3.0274\n",
      "Epoch 827/1000 - Loss: 0.3402 - Weights: [3.59901692 2.21328605] - Bias: -3.0297\n",
      "Epoch 828/1000 - Loss: 0.3400 - Weights: [3.60158252 2.21532604] - Bias: -3.0321\n",
      "Epoch 829/1000 - Loss: 0.3398 - Weights: [3.60414585 2.21736494] - Bias: -3.0344\n",
      "Epoch 830/1000 - Loss: 0.3397 - Weights: [3.60670691 2.21940272] - Bias: -3.0368\n",
      "Epoch 831/1000 - Loss: 0.3395 - Weights: [3.60926571 2.22143941] - Bias: -3.0391\n",
      "Epoch 832/1000 - Loss: 0.3394 - Weights: [3.61182225 2.22347499] - Bias: -3.0415\n",
      "Epoch 833/1000 - Loss: 0.3392 - Weights: [3.61437654 2.22550947] - Bias: -3.0438\n",
      "Epoch 834/1000 - Loss: 0.3390 - Weights: [3.61692857 2.22754286] - Bias: -3.0461\n",
      "Epoch 835/1000 - Loss: 0.3389 - Weights: [3.61947836 2.22957514] - Bias: -3.0485\n",
      "Epoch 836/1000 - Loss: 0.3387 - Weights: [3.62202591 2.23160633] - Bias: -3.0508\n",
      "Epoch 837/1000 - Loss: 0.3386 - Weights: [3.62457122 2.23363642] - Bias: -3.0532\n",
      "Epoch 838/1000 - Loss: 0.3384 - Weights: [3.62711429 2.23566542] - Bias: -3.0555\n",
      "Epoch 839/1000 - Loss: 0.3382 - Weights: [3.62965514 2.23769332] - Bias: -3.0578\n",
      "Epoch 840/1000 - Loss: 0.3381 - Weights: [3.63219376 2.23972013] - Bias: -3.0602\n",
      "Epoch 841/1000 - Loss: 0.3379 - Weights: [3.63473015 2.24174586] - Bias: -3.0625\n",
      "Epoch 842/1000 - Loss: 0.3378 - Weights: [3.63726433 2.24377049] - Bias: -3.0648\n",
      "Epoch 843/1000 - Loss: 0.3376 - Weights: [3.63979629 2.24579403] - Bias: -3.0671\n",
      "Epoch 844/1000 - Loss: 0.3374 - Weights: [3.64232605 2.24781648] - Bias: -3.0695\n",
      "Epoch 845/1000 - Loss: 0.3373 - Weights: [3.64485359 2.24983785] - Bias: -3.0718\n",
      "Epoch 846/1000 - Loss: 0.3371 - Weights: [3.64737893 2.25185813] - Bias: -3.0741\n",
      "Epoch 847/1000 - Loss: 0.3370 - Weights: [3.64990208 2.25387733] - Bias: -3.0764\n",
      "Epoch 848/1000 - Loss: 0.3368 - Weights: [3.65242303 2.25589545] - Bias: -3.0788\n",
      "Epoch 849/1000 - Loss: 0.3366 - Weights: [3.65494178 2.25791248] - Bias: -3.0811\n",
      "Epoch 850/1000 - Loss: 0.3365 - Weights: [3.65745835 2.25992843] - Bias: -3.0834\n",
      "Epoch 851/1000 - Loss: 0.3363 - Weights: [3.65997274 2.26194331] - Bias: -3.0857\n",
      "Epoch 852/1000 - Loss: 0.3362 - Weights: [3.66248494 2.2639571 ] - Bias: -3.0880\n",
      "Epoch 853/1000 - Loss: 0.3360 - Weights: [3.66499497 2.26596982] - Bias: -3.0903\n",
      "Epoch 854/1000 - Loss: 0.3359 - Weights: [3.66750283 2.26798146] - Bias: -3.0926\n",
      "Epoch 855/1000 - Loss: 0.3357 - Weights: [3.67000851 2.26999203] - Bias: -3.0949\n",
      "Epoch 856/1000 - Loss: 0.3355 - Weights: [3.67251204 2.27200153] - Bias: -3.0972\n",
      "Epoch 857/1000 - Loss: 0.3354 - Weights: [3.6750134  2.27400995] - Bias: -3.0995\n",
      "Epoch 858/1000 - Loss: 0.3352 - Weights: [3.6775126 2.2760173] - Bias: -3.1018\n",
      "Epoch 859/1000 - Loss: 0.3351 - Weights: [3.68000966 2.27802358] - Bias: -3.1041\n",
      "Epoch 860/1000 - Loss: 0.3349 - Weights: [3.68250456 2.28002879] - Bias: -3.1064\n",
      "Epoch 861/1000 - Loss: 0.3348 - Weights: [3.68499731 2.28203293] - Bias: -3.1087\n",
      "Epoch 862/1000 - Loss: 0.3346 - Weights: [3.68748793 2.28403601] - Bias: -3.1110\n",
      "Epoch 863/1000 - Loss: 0.3345 - Weights: [3.6899764  2.28603802] - Bias: -3.1133\n",
      "Epoch 864/1000 - Loss: 0.3343 - Weights: [3.69246274 2.28803897] - Bias: -3.1156\n",
      "Epoch 865/1000 - Loss: 0.3341 - Weights: [3.69494695 2.29003885] - Bias: -3.1179\n",
      "Epoch 866/1000 - Loss: 0.3340 - Weights: [3.69742904 2.29203767] - Bias: -3.1202\n",
      "Epoch 867/1000 - Loss: 0.3338 - Weights: [3.69990899 2.29403543] - Bias: -3.1225\n",
      "Epoch 868/1000 - Loss: 0.3337 - Weights: [3.70238683 2.29603213] - Bias: -3.1248\n",
      "Epoch 869/1000 - Loss: 0.3335 - Weights: [3.70486256 2.29802777] - Bias: -3.1270\n",
      "Epoch 870/1000 - Loss: 0.3334 - Weights: [3.70733616 2.30002235] - Bias: -3.1293\n",
      "Epoch 871/1000 - Loss: 0.3332 - Weights: [3.70980767 2.30201588] - Bias: -3.1316\n",
      "Epoch 872/1000 - Loss: 0.3331 - Weights: [3.71227706 2.30400835] - Bias: -3.1339\n",
      "Epoch 873/1000 - Loss: 0.3329 - Weights: [3.71474435 2.30599977] - Bias: -3.1361\n",
      "Epoch 874/1000 - Loss: 0.3328 - Weights: [3.71720955 2.30799013] - Bias: -3.1384\n",
      "Epoch 875/1000 - Loss: 0.3326 - Weights: [3.71967265 2.30997944] - Bias: -3.1407\n",
      "Epoch 876/1000 - Loss: 0.3325 - Weights: [3.72213366 2.3119677 ] - Bias: -3.1430\n",
      "Epoch 877/1000 - Loss: 0.3323 - Weights: [3.72459258 2.31395491] - Bias: -3.1452\n",
      "Epoch 878/1000 - Loss: 0.3322 - Weights: [3.72704942 2.31594108] - Bias: -3.1475\n",
      "Epoch 879/1000 - Loss: 0.3320 - Weights: [3.72950418 2.31792619] - Bias: -3.1498\n",
      "Epoch 880/1000 - Loss: 0.3319 - Weights: [3.73195686 2.31991026] - Bias: -3.1520\n",
      "Epoch 881/1000 - Loss: 0.3317 - Weights: [3.73440747 2.32189328] - Bias: -3.1543\n",
      "Epoch 882/1000 - Loss: 0.3316 - Weights: [3.73685601 2.32387526] - Bias: -3.1566\n",
      "Epoch 883/1000 - Loss: 0.3314 - Weights: [3.73930248 2.32585619] - Bias: -3.1588\n",
      "Epoch 884/1000 - Loss: 0.3313 - Weights: [3.7417469  2.32783609] - Bias: -3.1611\n",
      "Epoch 885/1000 - Loss: 0.3311 - Weights: [3.74418925 2.32981494] - Bias: -3.1633\n",
      "Epoch 886/1000 - Loss: 0.3310 - Weights: [3.74662955 2.33179275] - Bias: -3.1656\n",
      "Epoch 887/1000 - Loss: 0.3308 - Weights: [3.74906779 2.33376952] - Bias: -3.1678\n",
      "Epoch 888/1000 - Loss: 0.3307 - Weights: [3.75150399 2.33574526] - Bias: -3.1701\n",
      "Epoch 889/1000 - Loss: 0.3305 - Weights: [3.75393814 2.33771996] - Bias: -3.1723\n",
      "Epoch 890/1000 - Loss: 0.3304 - Weights: [3.75637026 2.33969362] - Bias: -3.1746\n",
      "Epoch 891/1000 - Loss: 0.3302 - Weights: [3.75880033 2.34166625] - Bias: -3.1768\n",
      "Epoch 892/1000 - Loss: 0.3301 - Weights: [3.76122837 2.34363785] - Bias: -3.1791\n",
      "Epoch 893/1000 - Loss: 0.3299 - Weights: [3.76365438 2.34560841] - Bias: -3.1813\n",
      "Epoch 894/1000 - Loss: 0.3298 - Weights: [3.76607836 2.34757794] - Bias: -3.1836\n",
      "Epoch 895/1000 - Loss: 0.3296 - Weights: [3.76850032 2.34954644] - Bias: -3.1858\n",
      "Epoch 896/1000 - Loss: 0.3295 - Weights: [3.77092026 2.35151392] - Bias: -3.1881\n",
      "Epoch 897/1000 - Loss: 0.3293 - Weights: [3.77333818 2.35348036] - Bias: -3.1903\n",
      "Epoch 898/1000 - Loss: 0.3292 - Weights: [3.77575408 2.35544578] - Bias: -3.1925\n",
      "Epoch 899/1000 - Loss: 0.3290 - Weights: [3.77816798 2.35741017] - Bias: -3.1948\n",
      "Epoch 900/1000 - Loss: 0.3289 - Weights: [3.78057987 2.35937354] - Bias: -3.1970\n",
      "Epoch 901/1000 - Loss: 0.3287 - Weights: [3.78298976 2.36133588] - Bias: -3.1992\n",
      "Epoch 902/1000 - Loss: 0.3286 - Weights: [3.78539764 2.3632972 ] - Bias: -3.2015\n",
      "Epoch 903/1000 - Loss: 0.3284 - Weights: [3.78780354 2.3652575 ] - Bias: -3.2037\n",
      "Epoch 904/1000 - Loss: 0.3283 - Weights: [3.79020743 2.36721678] - Bias: -3.2059\n",
      "Epoch 905/1000 - Loss: 0.3282 - Weights: [3.79260934 2.36917504] - Bias: -3.2081\n",
      "Epoch 906/1000 - Loss: 0.3280 - Weights: [3.79500926 2.37113228] - Bias: -3.2104\n",
      "Epoch 907/1000 - Loss: 0.3279 - Weights: [3.7974072  2.37308851] - Bias: -3.2126\n",
      "Epoch 908/1000 - Loss: 0.3277 - Weights: [3.79980316 2.37504372] - Bias: -3.2148\n",
      "Epoch 909/1000 - Loss: 0.3276 - Weights: [3.80219714 2.37699791] - Bias: -3.2170\n",
      "Epoch 910/1000 - Loss: 0.3274 - Weights: [3.80458915 2.37895109] - Bias: -3.2192\n",
      "Epoch 911/1000 - Loss: 0.3273 - Weights: [3.80697919 2.38090326] - Bias: -3.2215\n",
      "Epoch 912/1000 - Loss: 0.3271 - Weights: [3.80936726 2.38285441] - Bias: -3.2237\n",
      "Epoch 913/1000 - Loss: 0.3270 - Weights: [3.81175337 2.38480455] - Bias: -3.2259\n",
      "Epoch 914/1000 - Loss: 0.3269 - Weights: [3.81413752 2.38675369] - Bias: -3.2281\n",
      "Epoch 915/1000 - Loss: 0.3267 - Weights: [3.81651971 2.38870181] - Bias: -3.2303\n",
      "Epoch 916/1000 - Loss: 0.3266 - Weights: [3.81889995 2.39064893] - Bias: -3.2325\n",
      "Epoch 917/1000 - Loss: 0.3264 - Weights: [3.82127824 2.39259504] - Bias: -3.2347\n",
      "Epoch 918/1000 - Loss: 0.3263 - Weights: [3.82365459 2.39454014] - Bias: -3.2369\n",
      "Epoch 919/1000 - Loss: 0.3261 - Weights: [3.82602899 2.39648424] - Bias: -3.2391\n",
      "Epoch 920/1000 - Loss: 0.3260 - Weights: [3.82840145 2.39842734] - Bias: -3.2413\n",
      "Epoch 921/1000 - Loss: 0.3259 - Weights: [3.83077197 2.40036943] - Bias: -3.2435\n",
      "Epoch 922/1000 - Loss: 0.3257 - Weights: [3.83314056 2.40231053] - Bias: -3.2457\n",
      "Epoch 923/1000 - Loss: 0.3256 - Weights: [3.83550722 2.40425062] - Bias: -3.2479\n",
      "Epoch 924/1000 - Loss: 0.3254 - Weights: [3.83787196 2.40618971] - Bias: -3.2501\n",
      "Epoch 925/1000 - Loss: 0.3253 - Weights: [3.84023476 2.4081278 ] - Bias: -3.2523\n",
      "Epoch 926/1000 - Loss: 0.3251 - Weights: [3.84259565 2.4100649 ] - Bias: -3.2545\n",
      "Epoch 927/1000 - Loss: 0.3250 - Weights: [3.84495462 2.412001  ] - Bias: -3.2567\n",
      "Epoch 928/1000 - Loss: 0.3249 - Weights: [3.84731168 2.41393611] - Bias: -3.2589\n",
      "Epoch 929/1000 - Loss: 0.3247 - Weights: [3.84966682 2.41587022] - Bias: -3.2611\n",
      "Epoch 930/1000 - Loss: 0.3246 - Weights: [3.85202006 2.41780334] - Bias: -3.2633\n",
      "Epoch 931/1000 - Loss: 0.3244 - Weights: [3.85437139 2.41973546] - Bias: -3.2654\n",
      "Epoch 932/1000 - Loss: 0.3243 - Weights: [3.85672083 2.4216666 ] - Bias: -3.2676\n",
      "Epoch 933/1000 - Loss: 0.3242 - Weights: [3.85906836 2.42359674] - Bias: -3.2698\n",
      "Epoch 934/1000 - Loss: 0.3240 - Weights: [3.86141399 2.42552589] - Bias: -3.2720\n",
      "Epoch 935/1000 - Loss: 0.3239 - Weights: [3.86375774 2.42745406] - Bias: -3.2742\n",
      "Epoch 936/1000 - Loss: 0.3237 - Weights: [3.8660996  2.42938124] - Bias: -3.2763\n",
      "Epoch 937/1000 - Loss: 0.3236 - Weights: [3.86843957 2.43130743] - Bias: -3.2785\n",
      "Epoch 938/1000 - Loss: 0.3235 - Weights: [3.87077765 2.43323264] - Bias: -3.2807\n",
      "Epoch 939/1000 - Loss: 0.3233 - Weights: [3.87311386 2.43515687] - Bias: -3.2829\n",
      "Epoch 940/1000 - Loss: 0.3232 - Weights: [3.87544819 2.43708011] - Bias: -3.2850\n",
      "Epoch 941/1000 - Loss: 0.3230 - Weights: [3.87778065 2.43900237] - Bias: -3.2872\n",
      "Epoch 942/1000 - Loss: 0.3229 - Weights: [3.88011124 2.44092365] - Bias: -3.2894\n",
      "Epoch 943/1000 - Loss: 0.3228 - Weights: [3.88243996 2.44284394] - Bias: -3.2916\n",
      "Epoch 944/1000 - Loss: 0.3226 - Weights: [3.88476682 2.44476326] - Bias: -3.2937\n",
      "Epoch 945/1000 - Loss: 0.3225 - Weights: [3.88709181 2.4466816 ] - Bias: -3.2959\n",
      "Epoch 946/1000 - Loss: 0.3224 - Weights: [3.88941495 2.44859897] - Bias: -3.2980\n",
      "Epoch 947/1000 - Loss: 0.3222 - Weights: [3.89173624 2.45051536] - Bias: -3.3002\n",
      "Epoch 948/1000 - Loss: 0.3221 - Weights: [3.89405567 2.45243077] - Bias: -3.3024\n",
      "Epoch 949/1000 - Loss: 0.3219 - Weights: [3.89637325 2.45434521] - Bias: -3.3045\n",
      "Epoch 950/1000 - Loss: 0.3218 - Weights: [3.89868899 2.45625867] - Bias: -3.3067\n",
      "Epoch 951/1000 - Loss: 0.3217 - Weights: [3.90100288 2.45817117] - Bias: -3.3088\n",
      "Epoch 952/1000 - Loss: 0.3215 - Weights: [3.90331493 2.46008269] - Bias: -3.3110\n",
      "Epoch 953/1000 - Loss: 0.3214 - Weights: [3.90562515 2.46199324] - Bias: -3.3131\n",
      "Epoch 954/1000 - Loss: 0.3213 - Weights: [3.90793354 2.46390282] - Bias: -3.3153\n",
      "Epoch 955/1000 - Loss: 0.3211 - Weights: [3.91024009 2.46581144] - Bias: -3.3174\n",
      "Epoch 956/1000 - Loss: 0.3210 - Weights: [3.91254482 2.46771909] - Bias: -3.3196\n",
      "Epoch 957/1000 - Loss: 0.3209 - Weights: [3.91484772 2.46962577] - Bias: -3.3217\n",
      "Epoch 958/1000 - Loss: 0.3207 - Weights: [3.9171488  2.47153149] - Bias: -3.3239\n",
      "Epoch 959/1000 - Loss: 0.3206 - Weights: [3.91944806 2.47343624] - Bias: -3.3260\n",
      "Epoch 960/1000 - Loss: 0.3204 - Weights: [3.9217455  2.47534003] - Bias: -3.3282\n",
      "Epoch 961/1000 - Loss: 0.3203 - Weights: [3.92404114 2.47724286] - Bias: -3.3303\n",
      "Epoch 962/1000 - Loss: 0.3202 - Weights: [3.92633496 2.47914472] - Bias: -3.3325\n",
      "Epoch 963/1000 - Loss: 0.3200 - Weights: [3.92862697 2.48104563] - Bias: -3.3346\n",
      "Epoch 964/1000 - Loss: 0.3199 - Weights: [3.93091719 2.48294557] - Bias: -3.3367\n",
      "Epoch 965/1000 - Loss: 0.3198 - Weights: [3.9332056  2.48484456] - Bias: -3.3389\n",
      "Epoch 966/1000 - Loss: 0.3196 - Weights: [3.93549221 2.48674259] - Bias: -3.3410\n",
      "Epoch 967/1000 - Loss: 0.3195 - Weights: [3.93777703 2.48863967] - Bias: -3.3431\n",
      "Epoch 968/1000 - Loss: 0.3194 - Weights: [3.94006006 2.49053579] - Bias: -3.3453\n",
      "Epoch 969/1000 - Loss: 0.3192 - Weights: [3.94234129 2.49243095] - Bias: -3.3474\n",
      "Epoch 970/1000 - Loss: 0.3191 - Weights: [3.94462074 2.49432516] - Bias: -3.3495\n",
      "Epoch 971/1000 - Loss: 0.3190 - Weights: [3.94689841 2.49621842] - Bias: -3.3517\n",
      "Epoch 972/1000 - Loss: 0.3188 - Weights: [3.9491743  2.49811073] - Bias: -3.3538\n",
      "Epoch 973/1000 - Loss: 0.3187 - Weights: [3.95144841 2.50000208] - Bias: -3.3559\n",
      "Epoch 974/1000 - Loss: 0.3186 - Weights: [3.95372074 2.50189249] - Bias: -3.3580\n",
      "Epoch 975/1000 - Loss: 0.3184 - Weights: [3.95599131 2.50378195] - Bias: -3.3601\n",
      "Epoch 976/1000 - Loss: 0.3183 - Weights: [3.9582601  2.50567046] - Bias: -3.3623\n",
      "Epoch 977/1000 - Loss: 0.3182 - Weights: [3.96052713 2.50755802] - Bias: -3.3644\n",
      "Epoch 978/1000 - Loss: 0.3180 - Weights: [3.96279239 2.50944464] - Bias: -3.3665\n",
      "Epoch 979/1000 - Loss: 0.3179 - Weights: [3.96505589 2.51133031] - Bias: -3.3686\n",
      "Epoch 980/1000 - Loss: 0.3178 - Weights: [3.96731764 2.51321504] - Bias: -3.3707\n",
      "Epoch 981/1000 - Loss: 0.3177 - Weights: [3.96957763 2.51509883] - Bias: -3.3728\n",
      "Epoch 982/1000 - Loss: 0.3175 - Weights: [3.97183587 2.51698167] - Bias: -3.3750\n",
      "Epoch 983/1000 - Loss: 0.3174 - Weights: [3.97409236 2.51886357] - Bias: -3.3771\n",
      "Epoch 984/1000 - Loss: 0.3173 - Weights: [3.97634711 2.52074454] - Bias: -3.3792\n",
      "Epoch 985/1000 - Loss: 0.3171 - Weights: [3.97860011 2.52262456] - Bias: -3.3813\n",
      "Epoch 986/1000 - Loss: 0.3170 - Weights: [3.98085137 2.52450364] - Bias: -3.3834\n",
      "Epoch 987/1000 - Loss: 0.3169 - Weights: [3.98310089 2.52638179] - Bias: -3.3855\n",
      "Epoch 988/1000 - Loss: 0.3167 - Weights: [3.98534868 2.528259  ] - Bias: -3.3876\n",
      "Epoch 989/1000 - Loss: 0.3166 - Weights: [3.98759473 2.53013528] - Bias: -3.3897\n",
      "Epoch 990/1000 - Loss: 0.3165 - Weights: [3.98983906 2.53201062] - Bias: -3.3918\n",
      "Epoch 991/1000 - Loss: 0.3163 - Weights: [3.99208166 2.53388503] - Bias: -3.3939\n",
      "Epoch 992/1000 - Loss: 0.3162 - Weights: [3.99432253 2.5357585 ] - Bias: -3.3960\n",
      "Epoch 993/1000 - Loss: 0.3161 - Weights: [3.99656169 2.53763105] - Bias: -3.3981\n",
      "Epoch 994/1000 - Loss: 0.3160 - Weights: [3.99879912 2.53950266] - Bias: -3.4002\n",
      "Epoch 995/1000 - Loss: 0.3158 - Weights: [4.00103484 2.54137334] - Bias: -3.4023\n",
      "Epoch 996/1000 - Loss: 0.3157 - Weights: [4.00326885 2.5432431 ] - Bias: -3.4044\n",
      "Epoch 997/1000 - Loss: 0.3156 - Weights: [4.00550115 2.54511192] - Bias: -3.4065\n",
      "Epoch 998/1000 - Loss: 0.3154 - Weights: [4.00773174 2.54697982] - Bias: -3.4086\n",
      "Epoch 999/1000 - Loss: 0.3153 - Weights: [4.00996062 2.5488468 ] - Bias: -3.4106\n",
      "Epoch 1000/1000 - Loss: 0.3152 - Weights: [4.0121878  2.55071284] - Bias: -3.4127\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression(learning_rate=0.1, epochs=1000)\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c44978dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "Weights: [4.0121878  2.55071284]\n",
      "Bias: -3.412735119158449\n"
     ]
    }
   ],
   "source": [
    "# Predict on the training set\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = np.mean(predictions == y)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Display the learned weights and bias\n",
    "print(\"Weights:\", model.weights)\n",
    "print(\"Bias:\", model.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0ab0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
